---
title: "ltvProject"
output: html_document
---


## R Markdown

Our client is an online greeting card company. The company offers monthly subscriptions at a rate of $1 per month for access to their eCard website. The client is interested in understanding the life-time value (ltv) of their customers.
The life-time value of a customer is defined as the total revenue earned by the company over the course of their relationship with the customer.
The enclosed (synthetic) data represent usage statistics for 10,000 customers. Usage is summarized at a daily level and covers a period of 4 years from 2011-01-01 to 2014-12-31.
The following is a description of each field captured in the enclosed data set containing a total of 10,000 customers.

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
| `id`       | A unique user identifier                                                            |
| `status`   | Subscription status ‘0’- new, ‘1’- open, ‘2’- cancelation event                     |
| `gender`   | User gender ‘M’- male, ‘F’- female                                                  |
| `date`     | Date of in which user ‘id’ logged into the site                                     |
| `pages`    | Number of pages visted by user ‘id’ on date ‘date’                                  |
| `onsite`   | Number of minutes spent on site by user ‘id’ on date ‘date’                         |
| `entered`  | Flag indicating whether or not user entered the send order path on date ‘date’      |
| `completed`| Flag indicating whether the user completed the order (sent an eCard)                |
| `holiday`  | Flag indicating whether at least one completed order included a holiday themed card |

We must preprocess the data to determine the following: 

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
| `lifespan` | The lifespan of each customer in days, for cancelled customers= cancelDate-openDate,|
|            | for open customers=maxDate-openDate+1/(cancelled customers/total customers)         |


```{r, message=FALSE}
library(tidyverse)
library(ggplot2)
library(ISLR)
library(partykit)
library(caret)
library(rpart)
library(randomForest)
library(pROC)
library(binaryLogic)
library(dplyr)
library(class)
library(DMwR)
library(nnet)
library(e1071)
library(ranger)
library(glmnet)
library(cluster)
library(ggdendro)
library(knitr)
library(readxl)
```

```{r, cache = TRUE}
# Importing the data directly from Excel
customer.data <- read_excel("ltv Dataset.xlsx", sheet = "Sheet1")
```

```{r, cache = TRUE}
# Transform the data to teh desired format
customer.data <- transform(
  customer.data,
  id=as.integer(id),
  status=as.integer(status),
  gender=as.factor(gender),
  date=as.Date(date),
  pages=as.integer(pages),
  onsite=as.integer(onsite),
  entered=as.integer(entered),
  completed=as.integer(completed),
  holiday=as.integer(holiday)
)
#Summarizing the raw data set we are using
kable(summary(customer.data), digits = c(3, 3, 3, 3), format = "pandoc")

```

```{r}
#processing the date
customer.data$date <- as.Date(customer.data$date,'%m/%d/%Y')
customer.data$month <- months(customer.data$date)
customer.data$year <- format(customer.data$date,format = '%Y')
```

```{r}
#calculate the average value
ltv.pages <- aggregate( pages ~ id+ month + year, customer.data, mean)
ltv.onsite <- aggregate( onsite ~ id + month + year, customer.data, mean)

#merger the table
ltv.m1 <- merge(x = ltv.pages, y = ltv.onsite, by = c('id','month','year'), all.x = TRUE)
```

```{r}
#sort the dataframe and export it
ltv.m1 <- ltv.m1[order(ltv.m1$id),]
ltv.m1

#Summary of the month based aggregated pre-processed data set
kable(summary(ltv.m1), digits = c(3, 3, 3, 3), format = "pandoc")

write.csv(ltv.m1,'ltv_modelOne.csv',row.names = FALSE)
```
```{r}

#find the overall login counts per month
ltv.logins <- aggregate(cbind(count = date) ~ id + month + year, 
          customer.data, 
          FUN = function(x){NROW(x)})
#order this by the id, year and month
ltv.logins <- ltv.logins[
  with(ltv.logins, order(id, year, match(ltv.logins$month, month.name))),]  %>% group_by(id)

#Summary of the login counts based on months per customer
kable(summary(ltv.logins), digits = c(3, 3, 3, 3), format = "pandoc")


```

```{r, cache=TRUE}
#convert the data from numeric to date type (duplicate) 
#customer.data$date <- as.Date(customer.data$date, origin = "1899-12-30")
#Calculate the customer lifespan 
#first group the data by ID to find the max and min date for a given customer
#along with the latest status 
customer.lifespan <- customer.data[, c("id", "date", "status")] %>% group_by(id)
customer.lifespan <-customer.lifespan %>% mutate(maxDate = max(date)) 
#we can asssume that a maxstatus of 0 => that the user just created the account and did not login 
#after, we will consider such a scenario as active
customer.lifespan <-customer.lifespan %>% mutate(status = ifelse(max(status)==0, 1,max(status))) 
customer.lifespan <- customer.lifespan %>% filter(date == min(date)) %>% distinct(id, .keep_all = TRUE) %>% rename(minDate = date)
#Subtract the maxDate and minDate to determine the number of days of subscription
customer.lifespan$subDays <- as.integer(difftime(customer.lifespan$maxDate, customer.lifespan$minDate, units = "days"))
#Determine the observed lifespan factor to be added
lifespanFraction <- 1/(with(1, sum(customer.data$status == 2))/10000)
#calculate the lifespan for the customers
customer.lifespan$lifespan <- customer.lifespan$subDays

#find the max and min Months and years
customer.lifespan$maxMonth <- months(customer.lifespan$maxDate)
customer.lifespan$minYear <- format(customer.lifespan$maxDate,format = '%Y')
customer.lifespan$minMonth <- months(customer.lifespan$minDate)
customer.lifespan$minYear <- format(customer.lifespan$minDate,format = '%Y')


#customer.lifespan$lifespan <- ifelse(customer.lifespan$status == 2, customer.lifespan$subDays, customer.lifespan$subDays + lifespanFraction)
#add this data to the main dataset 
customer.data$lifespan <- customer.lifespan$lifespan[match(customer.data$id,customer.lifespan$id)]


#Summary of the customer lifespan based pre-processed data set
kable(summary(customer.lifespan), digits = c(3, 3, 3, 3), format = "pandoc")

```

```{r}
#Determine the averages of pages, onsite and completed per customer over their lifespan
customer.overall.means <- aggregate(customer.data[, c("pages", "onsite", "completed")], list(customer.data$id), mean)
customer.overall.means <- customer.overall.means %>% rename(id = Group.1)
customer.overall.means$lastStatus <- customer.lifespan$status
customer.overall.means$lifespan <- customer.lifespan$lifespan
#determine the logins in the first month, last and the last but one 
customer.firstMonth.logins <- ltv.logins  %>%  filter(row_number()==1) %>% dplyr::select("id", "count")
customer.previousMonth.logins <- ltv.logins  %>%  filter(row_number()==n()-1) %>% dplyr::select("id",  "count")
customer.lastMonth.logins <- ltv.logins  %>%  filter(row_number()==n()) %>% dplyr::select("id", "count")

#determine the login ratios of lastMonth to first and the last month to the last but on
len = length(customer.overall.means$id)

for (i in seq(length(customer.overall.means$id))) {
  curId <- customer.overall.means$id[i]
  lastMonthLogins <- customer.lastMonth.logins[which(customer.lastMonth.logins$id==curId),2]
  firstMonthLogins <- customer.firstMonth.logins[which(customer.firstMonth.logins$id==curId),2]
  prevMonthLogins <- customer.previousMonth.logins[which(customer.previousMonth.logins$id==curId),2]
  if (is.na(prevMonthLogins$count[1])){
    #print(curId)
    prevMonthLogins <- lastMonthLogins
  }
  customer.overall.means$lastToFirstLoginRatio[i] <- as.numeric(lastMonthLogins/firstMonthLogins)
  customer.overall.means$lastToPrevLoginRatio[i] <- as.numeric(lastMonthLogins/prevMonthLogins)
}


#Summary of the customer average site usage over their lifespan
kable(summary(customer.overall.means), digits = c(3, 3, 3, 3), format = "pandoc")


```

Before using the predictors from the `customer.overall.means` table we must ensure that there is minimum co-relation between the terms. 

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = pmax(1, cex.cor * r))
}

# Use panel.cor to display correlations in lower panel.
pairs(customer.overall.means[,c(-1)], lower.panel = panel.cor) 

```
- From the above plots, we see that most of the predictors have very low correlation among themselves. While `pages` and `completed` have a .76 correlation between them, we still consider both of them as part of the model as the value is not too high to imply complete correlation. Hence removing either could cause the model to miss out on certain insights.

```{r, cache = TRUE}
# Add 2 columns in the dataframe representing completed/holiday and onsite/entered
ltv_afterProcess <- transform(
  customer.data,
  CompletedVSHoliday=as.integer(entered)/as.integer(holiday),
  OnsiteVSEntered=as.integer(onsite)/as.integer(entered)
)

#Summary of the complete data after pre-processing
kable(summary(ltv_afterProcess), digits = c(3, 3, 3, 3), format = "pandoc")

```

```{r, cache = TRUE}
# calculate the ratio between sum of all entered and sum of all completed
SumEnteredVSCompleted <- sum(ltv_afterProcess$entered)/sum(ltv_afterProcess$completed)
SumEnteredVSCompleted
```

```{r, cache = TRUE}
# create a new dataframe representing the aggregated summation of each variable per customer
aggregatedCustomerSums <- aggregate(cbind(PagesSum=ltv_afterProcess$pages, OnsiteSum=ltv_afterProcess$onsite, EnteredSum=ltv_afterProcess$entered, CompletedSum=ltv_afterProcess$completed, HolidaySum=ltv_afterProcess$holiday), by=list(Customerid=ltv_afterProcess$id), FUN=sum)
aggregatedCustomerSums<-merge(x = aggregatedCustomerSums, y = customer.data, intersect(names(aggregatedCustomerSums), names(customer.data)), by.x = "Customerid", by.y = "id", all.x=TRUE)[,c(names(aggregatedCustomerSums), "gender")]%>% distinct(Customerid, .keep_all=TRUE)
aggregatedCustomerSums <- transform(
  aggregatedCustomerSums,
  gender = as.factor(gender),
  status = customer.lifespan$status,
  lifespan = customer.lifespan$lifespan,
  decisiveratio = CompletedSum / EnteredSum
)
aggregatedCustomerSums <- rename(aggregatedCustomerSums, id = Customerid, pages = PagesSum, onsite = OnsiteSum, entered = EnteredSum, completed = CompletedSum, holiday = HolidaySum)

#Summary of the aggregated summation of each customer 
kable(summary(aggregatedCustomerSums), digits = c(3, 3, 3, 3), format = "pandoc")
```

```{r}
classMetrics <- function(conf.mat) {
  n <- sum(conf.mat)
  
  if (nrow(conf.mat) == 2) {
    accuracy <- (conf.mat[2,2] + conf.mat[1,1])/n
    sensitivity <- conf.mat[2,2]/(conf.mat[2,2]+conf.mat[1,2])
    specificity <- conf.mat[1,1]/(conf.mat[1,1]+conf.mat[2,1])
    ppv <- conf.mat[2,2]/(conf.mat[2,2]+conf.mat[2,1])
    npv <- conf.mat[1,1]/(conf.mat[1,1]+conf.mat[1,2]) 
  } else if (nrow(conf.mat) == 3) {
    accuracy <- (conf.mat[2,2] + conf.mat[1,1] + conf.mat[3,3])/n
    sensitivity <- conf.mat[3,3]/(conf.mat[3,3]+conf.mat[2,3]+conf.mat[1,3])
    specificity <- (conf.mat[1,2]+conf.mat[1,1]+conf.mat[2,1]+conf.mat[2,2])/(conf.mat[3,2]+conf.mat[2,2]+conf.mat[1,2]+conf.mat[3,1]+conf.mat[2,1]+conf.mat[1,1])
    ppv <- conf.mat[3,3]/(conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3])
    npv <- (conf.mat[1,2]+conf.mat[1,1]+conf.mat[2,1]+conf.mat[2,2])/(conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3])
  } else if (nrow(conf.mat) == 4) {
    accuracy <- (conf.mat[2,2] + conf.mat[1,1] + conf.mat[3,3]+ conf.mat[4,4])/n
    sensitivity <- conf.mat[4,4]/(conf.mat[1,4]+conf.mat[2,4]+conf.mat[3,4]+conf.mat[4,4])
    specificity <- (conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3])/(conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3]+conf.mat[4,1]+conf.mat[4,2]+conf.mat[4,3])
    ppv <- conf.mat[4,4]/(conf.mat[4,1]+conf.mat[4,2]+conf.mat[4,3]+conf.mat[4,3]) 
    npv <- (conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3])/(conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3]+conf.mat[1,4]+conf.mat[2,4]+conf.mat[3,4]) 
  }

  result <- data.frame()
  result <- data.frame("value" = c(accuracy, sensitivity, specificity,ppv,npv))
  row.names(result) <- c("accuracy", "sensitivity", "specificity","ppv","npv")
  
  return(result)
}
```

## 1.	Develop an attrition model, to predict whether a customer will cancel their subscription in the near future. Characterize your model performance.

#First Method: predict whether a customer will cancel their subscription in the near future based on different segments customer

We will try to determine if we can segment the customers into buckets and determine 
if any behaviour related to their average online time, completed orders can be used to 
predict whether a customer will cancel their subscription in the near future

- First pass analysis of the predictors that would be used via Clustering and then assosiate the
users into the appropriate segments:
`Active`  - Customers who are actively using the website and likely to keep subscribing
`Napping` - Customers who are mostly active but have a few days of almost 0 activity. They are unlikely to cancel their subscription in the near future
`Sleepin` - Customers who are not very active and are more likely to leave the subscription in the coming months
`Cancelled` - Customers who have cancelled and will cancel for sure.
 

```{r}
std.customer <- na.omit(customer.overall.means) # listwise deletion of missing
std.customer <- scale(std.customer) # standardize variables
wss <- (nrow(std.customer)-1)*sum(apply(std.customer,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(std.customer,
   centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
km.res <- kmeans(std.customer, 4, nstart = 25)
str(km.res)
clusplot(std.customer, km.res$cluster, color=TRUE, shade=TRUE,
   labels=2, lines=0)
```
 - K-Means seems too crowded and not very interpretatble. Let us try Heirarchical Clustering

```{r}

set.seed(30)
#Heirarchical Clustering
# we create a 100% data partition from the subset of customers who cancelled
cancelled.customers = createDataPartition(customer.overall.means$id[which(customer.overall.means$lastStatus == 2)],l=F, p = 1)
# we create a 100% data partition from the subset of customers who are active
active.customers = createDataPartition(customer.overall.means$id[which(customer.overall.means$lastStatus == 1)],l=F, p = 1)

customer.train <- rbind(active.customers, cancelled.customers)

scalled.customer = scale(customer.overall.means[,-1])
cancelled.customers.train = customer.overall.means[customer.train,-1 ]
#cancelled.customers.test = customer.overall.means[-customer.train, -1]

scalled.customer.train  = scalled.customer[customer.train, ]
# Compute distance metrics on the standardized customer data
distanceMatrix = dist(scalled.customer.train)

# Perform hierarchical clustering on distance metrics
hierarchical.cluster <- hclust(distanceMatrix, method = 'ward.D2')
# Build dendrogram object from hierarchical.cluster results
hierarchical.dendogram <- as.dendrogram(hierarchical.cluster)
# Extract the data (for rectangular lines)
hierarchical.dendogram <- dendro_data(hierarchical.dendogram, type = "rectangle")

names(hierarchical.dendogram)
#head(hierarchical.dendogram$segments)
head(hierarchical.dendogram$labels)

# Plot the dendogram
p <- ggplot(hierarchical.dendogram$segments) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend))+
  geom_text(data = hierarchical.dendogram$labels, aes(x, y, label = label),
            hjust = 1, angle = 90, size = 3)+
  ylim(-3, 15)+ ggtitle("Dendogram for Customer Segmentation")
print(p)
```
#The dendogram is too crowded and so we first try 5 segments and view the data

```{r}
members = cutree(hierarchical.cluster, k = 5)
aggregate(cancelled.customers.train, by = list(members), mean)
```
 - We can try to understand the profile of each segment.
 - Customer falling under segment/group2 2 and 4 are likely to have left or leave the subscription (in a month or two). The number of pages visited on average is the least and their life span is large. These are customers who most likely got bored or found other resources. The latter ratio of last month to prev seems to have increased by almost 100% when comapred to the last to first month ratio. 
 - Similarly, we see how customers belonging to the segment/group 1 have an average status towards 2. Their last month to first month login ratio as well as the prev to last month ratio is the highest. We can say that customers that come under this segment are likely to unscribe from the e-card greeting subscription. 

- Let us try decreasing the segments to 4 to see if more distinct status based segments can be obtained 
```{r}
# decreasing the segments to 4
members = cutree(hierarchical.cluster, k = 4)
segmented.customers <- as.data.frame(aggregate(cancelled.customers.train, by = list(members), mean))
segmented.customers <- segmented.customers %>% rename(Type = Group.1)
segmented.customers$Type <- c("Sleeping", "Cancelled", "Active", "Napping" )
segmented.customers
```
- We are able to see 4 disticnt groups and hence segregate the users into one of the categories - `Sleeping`, `Cancelled`, `Napping` and `Active`. We assign these categories to the respective users.
 - In general we notice that as the lifespan increases many customers tend to stop/cancel the subscription. This is alarming to the company as it is clear that more effort must be maintained in retaining current subscribers. A clear indication that customers would leave based on increasing lifespan is the difference between the two ratios. Larger the lastToPrevLogin ratio compared to the lastToFirst the more likely that the customer would stop the subscription. 
 - However, we notice that customers are more likely to stay on, even if their lifespan on average is large, if their browsing ratios are maintained within a 50% to 80% range.


```{r}
#Our train set contains all 10,000 users
cancelled.customers.train$segment <- members

#Summary of the customer segmentation data set 
kable(summary(cancelled.customers.train), digits = c(3, 3, 3, 3), format = "pandoc")
```
 
 - The below values refer to the segments:
  - 1 : `Sleeping`
  - 2 : `Cancelled`
  - 3 : `Active`
  - 4 : `Napping`  

#QQ plot visualization
  
construct the data to draw the QQ plot to examine the performance of our group
```{r}
#aggregate the dta
aggregate_customer <- cancelled.customers.train
aggregate_customer$segment.label <- ifelse(aggregate_customer$segment == 1,'sleeping',ifelse(aggregate_customer$segment == 2,'Cancelled',ifelse(aggregate_customer$segment == 3,'Active','Napping')
))
aggregate_customer$status.label <- ifelse(aggregate_customer$lastStatus == 1,'Active User','Non-Active User')

```


Compare the distribution of the original status and the clustering segment. We want to see the differences of order completed based on their qunatile distribution.
```{r}
# calculate the normal theoretical quantiles per group
df1 <- ddply(.data = aggregate_customer, .variables = .(status.label,segment.label), function(dat){
             q <- qqnorm(dat$completed, plot = FALSE)
             dat$xq <- q$x
             dat
}
)

# plot the sample values against the theoretical quantiles
ggplot(data = df1, aes(x = xq, y = completed)) +
  geom_point() +
  labs(title = 'QQ plots', x = 'Normal Quantiles', y = 'Data Completed Quantiles')+
  facet_grid(status.label ~ segment.label)
```

```{r}
#normalize the lifespan
# standardize the birth weights
aggregate_customer = mutate(aggregate_customer, 
                 lifespan.norm = (lifespan - min(lifespan,na.rm = TRUE))/
                   (max(lifespan,na.rm = TRUE) - min(lifespan,na.rm = TRUE)))

```

```{r}
# calculate the normal theoretical quantiles per group
df2 <- ddply(.data = aggregate_customer, .variables = .(status.label,segment.label), function(dat){
             q <- qqnorm(dat$lifespan.norm, plot = FALSE)
             dat$xq <- q$x
             dat
}
)

# plot the sample values against the theoretical quantiles
ggplot(data = df2, aes(x = xq, y = lifespan.norm)) +
  geom_point() +  
  labs(title = 'QQ plots', x = 'Normal Quantiles', y = 'lifespan Quantiles')+
  facet_grid(status.label ~ segment.label)
```


#Based of the observation of the qunatile plot, we can notise that our clustering performance is great. 
#Further explanation would be written later

# Predicting via Random Forest
```{r, cache=TRUE}

set.seed(1)
# we create a 70:30 data partition from the subset of customers
train.segments = sample(1:nrow(cancelled.customers.train), nrow(cancelled.customers.train)*2/3)

customer.segements.train <- cancelled.customers.train[train.segments, -4]
customer.segements.test <- cancelled.customers.train[-train.segments, -4]

# Random Forest 

customer.segements.rf <- randomForest(as.factor(customer.segements.train$segment) ~ . ,data=customer.segements.train, importance=TRUE, ntree=150)
customer.segements.rf 
#plotting the importance of the variables in the model
varImpPlot(customer.segements.rf)

#creating a model to predict the segments that would move into cancellled 
customer.segements.rf.predict <- predict(customer.segements.rf, customer.segements.test)
customer.segements.rf.table <- table(customer.segements.rf.predict, customer.segements.test$segment)
customer.segements.rf.table

# display the measurement of confusion martixs
classMetrics(customer.segements.rf.table)
```
#SVM performance for the above

```{r}
#Creating the model
customer.segements.svm <-svm(as.factor(customer.segements.train$segment) ~ . , data = customer.segements.train)
customer.segements.svm
#We now develop the predict model given the svm model
customer.segements.svm.pred <- predict(customer.segements.svm, customer.segements.test)
#Confusion matric for the same
conf.mat.segments.svm<-table(customer.segements.svm.pred, customer.segements.test$segment)
conf.mat.segments.svm

# display the measurement of confusion martixs
classMetrics(conf.mat.segments.svm)
```
- The accuracy is only 73.99 %. Let us try tuning the model for better prediction rates

```{r, cache=TRUE, eval=FALSE}
#Parameter tuning - takes 30 minutes almost 
customer.seg.svm.tuned <-tune.svm(customer.segements.train, as.factor(customer.segements.train$segment), gamma=c(0.1, 1, 10), cost=10^(-1:2))
print(customer.seg.svm.tuned)
```

```{r, eval=FALSE}
#View how the performance changes-  Darker regions indicate better accuracy.
plot(customer.seg.svm.tuned)

#Determine the prediction using the best model
customer.seg.svm.best <- customer.seg.svm.tuned$best.model
customer.seg.svm.best.pred <- predict(customer.seg.svm.best, customer.segements.test) 
#print the confusion matrix
conf.mat.svm.best<-table(customer.seg.svm.best.pred, customer.segements.test$segment)
conf.mat.svm.best

# display the measurement of confusion martixs
classMetrics(conf.mat.svm.best)
```

```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Class1.rf <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.rf.predict))
rs <- roc.Class1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Cluster-Classification ROC")
roc.Class1.svm <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.svm.pred))
rs <- roc.Class1.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
roc.Class1.svm.best <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.seg.svm.best.pred))
rs <- roc.Class1.svm.best[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
```

# Second Method: classification

```{r}
customer.classify <- customer.data[, c("id", "date", "status", "pages", "onsite", "entered", "completed", "holiday", "gender")] %>% group_by(id)
customer.classify <-customer.classify %>% mutate(avgOnsite = mean(onsite))
customer.classify <-customer.classify %>% mutate(medOnsite = median(onsite))
customer.classify <-customer.classify %>% mutate(sdOnsite = sd(onsite))
customer.classify <-customer.classify %>% mutate(skewOnsite = skewness(onsite))
customer.classify <-customer.classify %>% mutate(avgPages = mean(pages))
customer.classify <-customer.classify %>% mutate(medPages = median(pages))
customer.classify <-customer.classify %>% mutate(sdPages = sd(pages))
customer.classify <-customer.classify %>% mutate(skewPages = skewness(pages))
customer.classify <-customer.classify %>% mutate(avgEntered = mean(entered))
customer.classify <-customer.classify %>% mutate(avgCompleted = mean(completed))
customer.classify <-customer.classify %>% mutate(avgHoliday = mean(holiday))
customer.classify<-customer.classify %>% mutate(enterPerPage = mean(entered/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% mutate(completePerEnter = sum(completed)/sum(entered))
customer.classify<-customer.classify %>% mutate(onsitePerEnter = sum(onsite)/sum(entered))
customer.classify<-customer.classify %>% mutate(onsitePerPage = mean(onsite/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% mutate(pagesPerHoliday = mean(holiday/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% mutate(onsitePerHoliday = mean(holiday/onsite, na.rm = TRUE))
customer.classify <-customer.classify %>% mutate(LastMonthOnsiteTime = tail(onsite, n=2)[1])
customer.classify <-customer.classify %>% mutate(LastMonthPagesViewed = tail(pages, n=2)[1])

customer.classify <- customer.classify %>% distinct(id, .keep_all = TRUE)
customer.classify <- transform(
  customer.classify,
  status = aggregatedCustomerSums$status,
  pages = aggregatedCustomerSums$pages,
  onsite = aggregatedCustomerSums$onsite,
  entered = aggregatedCustomerSums$entered,
  completed = aggregatedCustomerSums$completed,
  holiday = aggregatedCustomerSums$holiday
)

customer.classify<-transform(
  customer.classify,
  status = as.factor(status)
)

#Summary of the customer classification pre-processed data set  
kable(summary(customer.classify), digits = c(3, 3, 3, 3), format = "pandoc")

```

```{r}
#customer.classify.drop <- c("id","date","pages","onsite","entered","completed","holiday")
customer.classify.drop <- c("id","date")
customer.classify <- customer.classify[,!(names(customer.classify) %in% customer.classify.drop)]
```

```{r}
# Classification method for task 1
# Define training set
set.seed(42)
classify.train<-sample(1:nrow(customer.classify), nrow(customer.classify)*2/3)
customer.classify.train <- customer.classify[classify.train,]
customer.classify.test <- customer.classify[-classify.train,]
```

```{r,cache = true}
# Logistic Regression
customer.classify.logit <- glm(as.factor(status)~., data = customer.classify.train, family=binomial)
customer.classify.logit.probs <- predict(customer.classify.logit, customer.classify.test, type="response")
summary(customer.classify.logit)

customer.classify.logit.pred = rep("1",nrow(customer.classify.test))
customer.classify.logit.pred[customer.classify.logit.probs>0.5] = "2"

customer.classify.logit.table <- table(customer.classify.logit.pred, customer.classify.test$status)
customer.classify.logit.table

# display the measurement of confusion martixs
classMetrics(customer.classify.logit.table)
```

```{r,cache = true}
# Random Forest
# build the random forest model for classification
customer.classify.rf <- randomForest(status~., data=customer.classify.train, ntree=500, proximity=T,na.action = na.roughfix)
customer.classify.rf
customer.classify.rf.predict <- predict(customer.classify.rf, customer.classify.test)
customer.classify.rf.table <- table(customer.classify.rf.predict, customer.classify.test$status)
customer.classify.rf.table

# display the measurement of confusion martixs
classMetrics(customer.classify.rf.table)
```

```{r}
# Naive Bayes
customer.classify.nb <-naiveBayes(status ~., data = customer.classify.train, laplace=1)
summary(customer.classify.nb)
customer.classify.nb.pred <- predict(customer.classify.nb, customer.classify.test)

customer.classify.nb.table<-table(customer.classify.nb.pred, customer.classify.test$status)
customer.classify.nb.table

# display the measurement of confusion martixs
classMetrics(customer.classify.nb.table)
```

```{r}
#SVM
customer.classify.svm <-svm(status~ . , data = customer.classify.train, type = 'C-classification', kernel = 'radial')
customer.classify.svm.pred <- predict(customer.classify.svm, customer.classify.test)

customer.classify.svm.table<-table(customer.classify.svm.pred, customer.classify.test$status)
customer.classify.svm.table

# display the measurement of confusion martixs
classMetrics(customer.classify.svm.table)
```

```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Class2.rf <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.rf.predict))
rs <- roc.Class2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Direct Classification ROC")
roc.Class2.logit <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.logit.pred))
rs <- roc.Class2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Class2.nb <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.nb.pred))
rs <- roc.Class2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Class2.svm <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.svm.pred))
rs <- roc.Class2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
```


## 2.	Develop a model for estimating the ltv of a customer. Characterize your model performance.

```{r}
```

## 3.	Develop a customer segmentation scheme. Include in this scheme the identification of sleeping customers, those that are no longer active but have not canceled their account.

# Segmentation 1: Segmentation 1: Regular(users who have completed regularly irrespective of holidays), Sleeping, Holiday User(holiday based customers),  Inactive (canceled)

- Variables: Completed, pages, onsite, entered
- Classification label: Regular/Sleeping/Inactive
  - 3: if the customer has status as 2 or if they have not visited the website on the given date, then customer is inactive.
  - 2: if the customer has browsed the website >60 days of `12/31/2014` then classify the customer as sleeping.
  - 1: if the customer has recently browsed the website has been active within 60 days of `12/31/2014` then classify the customer as active.

- data preprocssing:
```{r}
aggregatedCustomerSums$holiday.ratio <- aggregatedCustomerSums$holiday/aggregatedCustomerSums$completed
summary(aggregatedCustomerSums$holiday.ratio)
```
```{r}
aggregatedCustomerSums$holiday.user <- ifelse(aggregatedCustomerSums$holiday.ratio>0.4573,1,0)
```

```{r}
width = length(customer.data)
len = length(customer.data$id)
user.type = rep(0, times = len)
previd = customer.data[1][1]
startid = previd
for(i in seq(len)){
  startid = customer.data[i,1]
  if(customer.data[i,2] == 2){
    user.type[i] = 3
  }else if(startid!=previd){
    diff = (as.Date('12/31/2014','%m/%d/%Y') - customer.data[i-1,4])
    if(diff>60){
      user.type[i-1] = 2
      user.type[i] = 1
    }else{
      user.type[i] = 1
    }
  }else{
    user.type[i] = 1
  }
  previd = startid
}
customer.data$userType <- user.type
```


```{r}
#select the data we need, we do not want to overfit the model, and hence will only include data only the 
# maxDate related data for the each user.
customer.data.segOne <- customer.data %>% group_by(id) %>% filter(date == max(date)) 
customer.data.segOne <- subset(customer.data.segOne,select = c('pages','onsite', 'userType'))#, 'entered', 'completed'))

#Summary of the customer classification for differnet user type  
kable(summary(customer.data.segOne), digits = c(3, 3, 3, 3), format = "pandoc")

#split into training and test dataset
customer.data.segOne <- transform(
  customer.data.segOne,
  pages=as.integer(pages),
  onsite=as.integer(onsite),
  userType = as.factor(userType)
)

set.seed(1)
dt = sort(sample(nrow(customer.data.segOne), nrow(customer.data.segOne)*.7))
train.segOne<-customer.data.segOne[dt,]
test.segOne<-customer.data.segOne[-dt,]
```

#random forest
```{r}
customer.segOne.rf <- randomForest(
  as.factor(userType) ~ ., 
  data = train.segOne, 
  importance = TRUE,
  num.trees = 500
)

customer.segOne.rf

varImpPlot(customer.segOne.rf)

customer.segOne.pred <- predict(customer.segOne.rf, test.segOne)
customer.segOne.rfResult<- table(test.segOne$userType, customer.segOne.pred)
customer.segOne.rfResult

# display the measurement of confusion martixs
classMetrics(customer.segOne.rfResult)
```

# Logistic Regression

```{r}
#create the logistic regression model with output as userType and inputs as pages, onsite, entered and completed.
customer.segOne.lr <- multinom(train.segOne$userType ~ . , data = train.segOne)
customer.segOne.lr
#test the model classification on the test data
customer.segOne.lr.pred <- predict(customer.segOne.lr,newdata=test.segOne)
#create a confusion matrix
customer.segOne.lr.conf <-table(customer.segOne.lr.pred, test.segOne$userType)
prop.table(customer.segOne.lr.conf)

# display the measurement of confusion martixs
classMetrics(customer.segOne.lr.conf)
```

# Naive Bayes

```{r}
#Construct a naive bayes classification model on the train data set
customer.segOne.nb <-naiveBayes(train.segOne$userType ~ ., data = train.segOne)
customer.segOne.nb
#test the model classification on the test data
customer.segOne.nb.pred <- predict(customer.segOne.nb, newdata=test.segOne)
#create a confusion matrix
customer.segOne.nb.conf <-table(customer.segOne.nb.pred, test.segOne$userType)
prop.table(customer.segOne.nb.conf)

# display the measurement of confusion martixs
classMetrics(customer.segOne.nb.conf)
```
```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Seg1.rf <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.pred))
rs <- roc.Seg1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 1 ROC")
roc.Seg1.logit <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.lr.pred))
rs <- roc.Seg1.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg1.nb <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.nb.pred))
rs <- roc.Seg1.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
```

# Segmentation 2: Decisive customers, Tentative customers, Hesitant customers
- Variables: Gender, onsite, pages, entered, completed
- Classification label: completed / entered 
  - 2: if the `decisiveratio` of that customer is greater or equal to `r summary(aggregatedCustomerSums$decisiveratio)[5]` then we classfy the customer as decisive
  - 1: if the `decisiveratio` of that customer fall in the range of `r summary(aggregatedCustomerSums$decisiveratio)[2]` and `r summary(aggregatedCustomerSums$decisiveratio)[5]`, then we classfy the customer as tentative
  - 0: if the `decisiveratio` of that customer is smaller than `r summary(aggregatedCustomerSums$decisiveratio)[2]` , then we classfy the customer as hesitant

```{r}
summary(aggregatedCustomerSums$decisiveratio)
```


```{r}
# create data labels 
decisivelabel <- with(aggregatedCustomerSums, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[5], 2, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[2],1,0)))
# merge the created label with selected data
decisive.data <- data.frame(aggregatedCustomerSums[c("pages", "onsite","holiday","gender","lifespan")], decisivelabel = as.factor(decisivelabel))
set.seed(42)
# separate data into train, test data
#randomly get 2/3 data of each label into train data, 1/3 data of each label into test data
hesitant<-subset(decisive.data, decisivelabel == 0)
tentative<-subset(decisive.data, decisivelabel == 1)
decisive<-subset(decisive.data, decisivelabel == 2)
train.h<-hesitant[sample(nrow(hesitant),), ][c(1:1658), ]
test.h<-hesitant[sample(nrow(hesitant),), ][c(1659:2487), ]
train.t<-tentative[sample(nrow(tentative),), ][c(1:3155),]
test.t<-tentative[sample(nrow(tentative),), ][c(3156:4732),]
train.d<-decisive[sample(nrow(decisive),), ][c(1:1854),]
test.d<-decisive[sample(nrow(decisive),), ][c(1854:2781),]
decisive.train<-rbind(train.h, train.t, train.d)
decisive.test<-rbind(test.h, test.t, test.d)
```

```{r, cache = TRUE}
# Random Forest
# build the random forest model for classification
customer.rf <- randomForest(decisivelabel~., data=decisive.train, ntree=500, proximity=T)
customer.rf
customer.rf.predict <- predict(customer.rf, decisive.test)
customer.rf.table <- table(customer.rf.predict, decisive.test$decisivelabel)
customer.rf.table

# display the measurement of confusion martixs
classMetrics(customer.rf.table)
```


```{r}
# KNN
train_control <- trainControl(method = "cv", number = 10)
customer.knn <- train(decisivelabel~., data = decisive.train, trControl = train_control, method = "knn")
customer.knn
customer.knn.predict <- predict(customer.knn, decisive.test)
customer.knn.table <- table(customer.knn.predict, decisive.test$decisivelabel)
customer.knn.table

# display the measurement of confusion martixs
classMetrics(customer.knn.table)
```

```{r}
# Mulrinomial Logistic Regression
decisve.ml <- multinom(decisivelabel ~ . , data = decisive.train)
decisve.ml
logit.pred <- decisve.ml %>% predict(decisive.test)
conf.mat.logit<-table(logit.pred, decisive.test$decisivelabel)
conf.mat.logit

# display the measurement of confusion martixs
classMetrics(conf.mat.logit)
```

```{r}
# Naive Bayes
decisive.nb <-naiveBayes(decisivelabel ~ . , data = decisive.train, laplace=1)
decisive.nb.pred <- predict(decisive.nb, decisive.test)
conf.mat.nb<-table(decisive.nb.pred, decisive.test$decisivelabel)
conf.mat.nb

# display the measurement of confusion martixs
classMetrics(conf.mat.nb)
```


```{r}
#SVM
decisive.svm <-svm(decisivelabel ~ . , data = decisive.train, type = 'C-classification', kernel = 'radial')
decisive.svm.pred <- predict(decisive.svm, decisive.test)
conf.mat.svm<-table(decisive.svm.pred, decisive.test$decisivelabel)
conf.mat.svm

# display the measurement of confusion martixs
classMetrics(conf.mat.svm)
```

```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Seg2.rf <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.rf.predict))
rs <- roc.Seg2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 2 ROC")
roc.Seg2.knn <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.knn.predict))
rs <- roc.Seg2.knn[['rocs']]
plot(rs[[1]], col = "steelblue", lty = 3, add = TRUE)
roc.Seg2.logit <- multiclass.roc(decisive.test$decisivelabel, as.numeric(logit.pred))
rs <- roc.Seg2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg2.nb <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.nb.pred))
rs <- roc.Seg2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Seg2.svm <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.svm.pred))
rs <- roc.Seg2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
```
## Random forest performs the best

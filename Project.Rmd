---
title: "Data mining Group Project"
author: "Group Name: Venturers-Group 3
         Members: Sixuan Tian, Yi Chen Huang, Ruixin Huang, Anita Nelliat
         AndrewId: sixuant, yichenhu, ruixinh, anelliat" 
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: cerulean
    highlight: tango

---

# Project on Customer Analysis for an Online Greeting Card Company

## Problem Statement

Our client is an online greeting card company. The company offers monthly subscriptions at a rate of $1 per month for access to their eCard website. The client is interested in understanding the life-time value (ltv) of their customers.
The life-time value of a customer is defined as the total revenue earned by the company over the course of their relationship with the customer.
The `ltv Dataset.xlsx` dataset represents usage statistics for 10,000 customers. Usage is summarized at a daily level and covers a period of 4 years from 2011-01-01 to 2014-12-31.
The following is a description of each field captured in the enclosed data set containing a total of 10,000 customers.

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
| `id`       | A unique user identifier                                                            |
| `status`   | Subscription status ‘0’- new, ‘1’- open, ‘2’- cancelation event                     |
| `gender`   | User gender ‘M’- male, ‘F’- female                                                  |
| `date`     | Date of in which user ‘id’ logged into the site                                     |
| `pages`    | Number of pages visted by user ‘id’ on date ‘date’                                  |
| `onsite`   | Number of minutes spent on site by user ‘id’ on date ‘date’                         |
| `entered`  | Flag indicating whether or not user entered the send order path on date ‘date’      |
| `completed`| Flag indicating whether the user completed the order (sent an eCard)                |
| `holiday`  | Flag indicating whether at least one completed order included a holiday themed card |
|------------|-------------------------------------------------------------------------------------|

- Key tasks
  - Develop an attrition model, to predict whether a customer will cancel their subscription in the near future. Characterize your model performance.
  - Develop a model for estimating the ltv of a customer. Characterize your model performance.
  - Develop a customer segmentation scheme. Include in this scheme the identification of sleeping customers, those that are no longer active but have not canceled their account.

```{r, message=FALSE}
library(dplyr)
library(plyr)
library(reshape2)
library(tidyverse)
library(ggplot2)
library(ISLR)
library(partykit)
library(caret)
library(rpart)
library(randomForest)
library(pROC)
library(binaryLogic)
library(dplyr)
library(class)
library(DMwR)
library(nnet)
library(e1071)
library(ranger)
library(glmnet)
library(cluster)
library(ggdendro)
library(knitr)
library(readxl)
library(factoextra)
library(scales)
```

```{r, cache = TRUE}
# Importing the data directly from Excel
customer.data <- read_excel("ltv Dataset.xlsx", sheet = "Sheet1")
```

```{r, cache = TRUE}
# Transform the data to teh desired format
customer.data <- transform(
  customer.data,
  id=as.integer(id),
  status=as.integer(status),
  gender=as.factor(gender),
  date=as.Date(date),
  pages=as.integer(pages),
  onsite=as.integer(onsite),
  entered=as.integer(entered),
  completed=as.integer(completed),
  holiday=as.integer(holiday)
)
#Summarizing the raw data set we are using
kable(summary(customer.data), digits = c(3, 3, 3, 3), format = "markdown")

```
## Data pre-processing 

Before developing models to address the tasks, we must first pre-process the data. This is done by creating multiple subsets 
of the data, with aggregated or other statistical details.

We preprocess the main `customer.data` dataset and add the below columns: 

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
|  `month`   | The month of the corresponding date                                                 |
|  `year`    | The year of the corresponding date                                                  |
|------------|-------------------------------------------------------------------------------------|

```{r}
#processing the date
customer.data$date <- as.Date(customer.data$date,'%m/%d/%Y')
customer.data$month <- months(customer.data$date)
customer.data$year <- format(customer.data$date,format = '%Y')
```

We create a dataset, containing the averages of pages and onsite per customer on a monthly basis called `ltv.m1` dataset with the below columns: 

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
|   `id`     | The unique identifier of the customer                                               |
|  `month`   | The month when the customer logged in                                               |
|  `year`    | The corresponding year when the customer logged in                                  |
|  `pages`   | The average number of pages visited by the customer in the given month              |
| `onsite`   | The average number of minutes spent on the site by the customer in the given month  |
|------------|-------------------------------------------------------------------------------------|


```{r}
#calculate the average value
ltv.pages <- aggregate( pages ~ id+ month + year, customer.data, mean)
ltv.onsite <- aggregate( onsite ~ id + month + year, customer.data, mean)

#merger the table
ltv.m1 <- merge(x = ltv.pages, y = ltv.onsite, by = c('id','month','year'), all.x = TRUE)
```

```{r}
#sort the dataframe and export it
ltv.m1 <- ltv.m1[order(ltv.m1$id),]
#Summary of the month based aggregated pre-processed data set
kable(summary(ltv.m1), digits = c(3, 3, 3, 3), format = "markdown")

#
write.csv(ltv.m1,'ltv_modelOne.csv',row.names = FALSE)
```

Next, we create a dataset called `ltv.logins` which contains the number of times a customer accessed the site per month.
Given below are the columns: 

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
|   `id`     | The unique identifier of the customer                                               |
|  `month`   | The month when the customer logged in                                               |
|  `year`    | The corresponding year when the customer logged in                                  |
|  `count`   | The total number of times a customer visited the site in the given month            |
|------------|-------------------------------------------------------------------------------------|


```{r}

#find the overall login counts per month
ltv.logins <- aggregate(cbind(count = date) ~ id + month + year, 
          customer.data, 
          FUN = function(x){NROW(x)})
#order this by the id, year and month
ltv.logins <- ltv.logins[
  with(ltv.logins, order(id, year, match(ltv.logins$month, month.name))),]  %>% group_by(id)

#Summary of the login counts based on months per customer
kable(summary(ltv.logins), digits = c(3, 3, 3, 3), format = "markdown")


```

Since we are performing customer based analysis, the lifespan of the customer becomes an important characteristic that must be measure. We use the first and last recorded dates for each customer to determine this.
A dataset called `customer.lifespan` is created containing the below: 

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
|   `id`     | The unique identifier of the customer                                               |
|  `minDate` | The date when the customer joined the subscription                                  |
|  `maxDate` | The date the customer cancelled or the last recorded date the customer logged in    |
|  `status`  | The final status of the customer                                                    |
| `lifespan` | The lifespan of each customer in days, which is maxDate-firstDate                   |
|------------|-------------------------------------------------------------------------------------|

```{r, cache=TRUE}
#To calculate the customer lifespan we first group the data
#by ID to find the max and min date for a given customer
customer.lifespan <- customer.data[, c("id", "date", "status")] %>% group_by(id)
customer.lifespan <-customer.lifespan %>% dplyr::mutate(maxDate = max(date)) 

#we can asssume that a maxstatus of 0 => that the user just created 
#the account and did not loginafter, we will consider such a scenario as active
customer.lifespan <-customer.lifespan %>% dplyr::mutate(status = ifelse(max(status)==0, 1,max(status))) 
customer.lifespan <- customer.lifespan %>% dplyr::filter(date == min(date)) %>% dplyr::distinct(id, .keep_all = TRUE) %>% dplyr::rename(minDate = date)

#Subtract the maxDate and minDate to determine the number of days of subscription
customer.lifespan$lifespan <- as.integer(difftime(customer.lifespan$maxDate, customer.lifespan$minDate, units = "days"))

#add this data to the main dataset 
customer.data$lifespan <- customer.lifespan$lifespan[match(customer.data$id,customer.lifespan$id)]

#Summary of the customer lifespan based pre-processed data set
kable(summary(customer.lifespan), digits = c(3, 3, 3, 3), format = "markdown")

```

We have a dataset that defines the averages over a month based range, we now calculate the overall averages per customer for the `pages`, `onsite` and `completed` predictors. This is put into the `customer.overall.means` dataset with the following columns: 

|      Data Field       | Description                                                                         | 
|-----------------------|-------------------------------------------------------------------------------------|
|     `id`              | The unique identifier of the customer                                               |
|     `pages`           | The overall average number of pages visited by the customer.                        |
|     `onsite`          | The overall average number of minutes spent on the site by the customer.            |
|     `completed`       | The overall average completed orders by the customer.                               |
|     `lastStatus`      | The final status of the customer.                                                   |
|     `lifespan`        | The lifespan of the customer based on the first login to last login                 |
|`lastToFirstLoginRatio`| The ratio of the no. of logins in the last month to the first month of a customer   |
|`lastToPrevLoginRatio` | The ratio of the no. of logins in the last month to the previous to last month      |
|-----------------------|-------------------------------------------------------------------------------------|                                                                               

```{r}
#Determine the averages of pages, onsite and completed per customer over their lifespan
customer.overall.means <- aggregate(customer.data[, c("pages", "onsite", "completed")], list(customer.data$id), mean)
customer.overall.means <- customer.overall.means %>% dplyr::rename(id = Group.1)
customer.overall.means$lastStatus <- customer.lifespan$status
customer.overall.means$lifespan <- customer.lifespan$lifespan

#determine the logins in the first month, last and the last but one 
customer.firstMonth.logins <- ltv.logins  %>%  dplyr::filter(row_number()==1) %>% dplyr::select("id", "count")
customer.previousMonth.logins <- ltv.logins  %>%  dplyr::filter(row_number()==n()-1) %>% dplyr::select("id",  "count")
customer.lastMonth.logins <- ltv.logins  %>%  dplyr::filter(row_number()==n()) %>% dplyr::select("id", "count")

#determine the login ratios of lastMonth to first and the last month to the last but one month.
len = length(customer.overall.means$id)

for (i in seq(length(customer.overall.means$id))) {
  curId <- customer.overall.means$id[i]
  lastMonthLogins <- customer.lastMonth.logins[which(customer.lastMonth.logins$id==curId),2]
  firstMonthLogins <- customer.firstMonth.logins[which(customer.firstMonth.logins$id==curId),2]
  prevMonthLogins <- customer.previousMonth.logins[which(customer.previousMonth.logins$id==curId),2]
  if (is.na(prevMonthLogins$count[1])){
    #This value will be NA since for users who 
    #just logged in once there is no previous month
    prevMonthLogins <- lastMonthLogins
  }
  customer.overall.means$lastToFirstLoginRatio[i] <- as.numeric(lastMonthLogins/firstMonthLogins)
  customer.overall.means$lastToPrevLoginRatio[i] <- as.numeric(lastMonthLogins/prevMonthLogins)
}


#Summary of the customer average site usage over their lifespan
kable(summary(customer.overall.means), digits = c(3, 3, 3, 3), format = "markdown")


```

Before using the predictors from the `customer.overall.means` table we must ensure that there is minimum co-relation between the terms. 

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = pmax(1, cex.cor * r))
}

# Use panel.cor to display correlations in lower panel.
pairs(customer.overall.means[,c(-1)], lower.panel = panel.cor) 

```

- From the above plots, we see that most of the predictors have very low correlation among themselves. While `pages` and `completed` have a .76 correlation between them, we still consider both of them as part of the model as the value is not too high to imply complete correlation. Hence removing either could cause the model to miss out on certain insights.

- After the preliminary data processing we create an `ltv_afterProcess` dataset containing the original data from the `customer.data` dataset with the addition of `CompletedVSHoliday` and `OnsiteVSEntered` columns. 

|      Data Field    | Description                                                            | 
|--------------------|------------------------------------------------------------------------|
|`CompletedVSHoliday`| The ratio of the no. entered vs holiday e-cards attempted              |
| `OnsiteVSEntered`  | The ratio of the no. onsite vs entered attempts by the customer        |
|--------------------|------------------------------------------------------------------------| 

```{r, cache = TRUE}
# Add 2 columns in the dataframe representing completed/holiday and onsite/entered
ltv_afterProcess <- transform(
  customer.data,
  CompletedVSHoliday=as.integer(entered)/as.integer(holiday),
  OnsiteVSEntered=as.integer(onsite)/as.integer(entered)
)

#Summary of the complete data after pre-processing
kable(summary(ltv_afterProcess), digits = c(3, 3, 3, 3), format = "markdown")

```

```{r, cache = TRUE}
# calculate the ratio between sum of all entered and sum of all completed
SumEnteredVSCompleted <- sum(ltv_afterProcess$entered)/sum(ltv_afterProcess$completed)
SumEnteredVSCompleted
```

We then create the `aggregatedCustomerSums` dataframe which represents the sum of each variable - `pages`, `onsite`, `completed`, `entered` and `holiday` per customer. Note this is a summation.

|      Data Field       | Description                                                                         | 
|-----------------------|-------------------------------------------------------------------------------------|
|     `id`              | The unique identifier of the customer                                               |
|     `pages`           | The total number of pages visited by the customer.                                  |
|     `onsite`          | The total number of minutes spent on the site by the customer.                      |
|     `entered`         | The total number of sender entered orders by the customer.                          |
|     `completed`       | The total number of completed orders by the customer.                               |
|     `holiday`         | The total number of holiday orders by the customer.                                 |
|     `gender`          | User gender ‘M’- male, ‘F’- female.                                                 |
|     `status`          | The final status of the customer taken from the `customer.lifespan` dataset.        |
|     `lifespan`        | The lifespan of the customer taken from the `customer.lifespan` dataset.            |
|     `decisiveRatio`   | The degree to which customers are hestitant to complete the order. This is          | 
|                       | calculated as Sum(`completed`)/Sum(`entered`) for each customer.                    |
|-----------------------|-------------------------------------------------------------------------------------|


```{r, cache = TRUE}
# create a new dataframe representing the aggregated summation of each variable per customer
aggregatedCustomerSums <- aggregate(cbind(PagesSum=ltv_afterProcess$pages, OnsiteSum=ltv_afterProcess$onsite, EnteredSum=ltv_afterProcess$entered, CompletedSum=ltv_afterProcess$completed, HolidaySum=ltv_afterProcess$holiday), by=list(Customerid=ltv_afterProcess$id), FUN=sum)
#merge this with the customer data based on id, to retrive the gender column.
aggregatedCustomerSums<-merge(x = aggregatedCustomerSums, y = customer.data, intersect(names(aggregatedCustomerSums), names(customer.data)), by.x = "Customerid", by.y = "id", all.x=TRUE)[,c(names(aggregatedCustomerSums), "gender")]%>% dplyr::distinct(Customerid, .keep_all=TRUE)

aggregatedCustomerSums <- transform(
  aggregatedCustomerSums,
  gender = as.factor(gender),
  status = customer.lifespan$status,
  lifespan = customer.lifespan$lifespan,
  decisiveratio = CompletedSum / EnteredSum
)
aggregatedCustomerSums <- dplyr::rename(aggregatedCustomerSums, id = Customerid, pages = PagesSum, onsite = OnsiteSum, entered = EnteredSum, completed = CompletedSum, holiday = HolidaySum)

#Summary of the aggregated summation of each customer 
kable(summary(aggregatedCustomerSums), digits = c(3, 3, 3, 3), format = "markdown")
```

Given below is the utility method to print out the performance metrics (Accuracy, Sensitivity, Specificity, PPV and NPV) for the models.

```{r}
classMetrics <- function(conf.mat) {
  n <- sum(conf.mat)
  
  if (nrow(conf.mat) == 2) {
    accuracy <- (conf.mat[2,2] + conf.mat[1,1])/n
    sensitivity <- conf.mat[2,2]/(conf.mat[2,2]+conf.mat[1,2])
    specificity <- conf.mat[1,1]/(conf.mat[1,1]+conf.mat[2,1])
    ppv <- conf.mat[2,2]/(conf.mat[2,2]+conf.mat[2,1])
    npv <- conf.mat[1,1]/(conf.mat[1,1]+conf.mat[1,2]) 
  } else if (nrow(conf.mat) == 3) {
    accuracy <- (conf.mat[2,2] + conf.mat[1,1] + conf.mat[3,3])/n
    sensitivity <- conf.mat[3,3]/(conf.mat[3,3]+conf.mat[2,3]+conf.mat[1,3])
    specificity <- (conf.mat[1,2]+conf.mat[1,1]+conf.mat[2,1]+conf.mat[2,2])/(conf.mat[3,2]+conf.mat[2,2]+conf.mat[1,2]+conf.mat[3,1]+conf.mat[2,1]+conf.mat[1,1])
    ppv <- conf.mat[3,3]/(conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3])
    npv <- (conf.mat[1,2]+conf.mat[1,1]+conf.mat[2,1]+conf.mat[2,2])/(conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3])
  } else if (nrow(conf.mat) == 4) {
    accuracy <- (conf.mat[2,2] + conf.mat[1,1] + conf.mat[3,3]+ conf.mat[4,4])/n
    sensitivity <- conf.mat[4,4]/(conf.mat[1,4]+conf.mat[2,4]+conf.mat[3,4]+conf.mat[4,4])
    specificity <- (conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3])/(conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3]+conf.mat[4,1]+conf.mat[4,2]+conf.mat[4,3])
    ppv <- conf.mat[4,4]/(conf.mat[4,1]+conf.mat[4,2]+conf.mat[4,3]+conf.mat[4,3]) 
    npv <- (conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3])/(conf.mat[1,1]+conf.mat[1,2]+conf.mat[1,3]+conf.mat[2,1]+conf.mat[2,2]+conf.mat[2,3]+conf.mat[3,1]+conf.mat[3,2]+conf.mat[3,3]+conf.mat[1,4]+conf.mat[2,4]+conf.mat[3,4]) 
  }

  result <- data.frame()
  result <- data.frame("value" = c(accuracy, sensitivity, specificity,ppv,npv))
  row.names(result) <- c("accuracy", "sensitivity", "specificity","ppv","npv")
  
  return(result)
}
```

## 1.	Develop an attrition model, to predict whether a customer will cancel their subscription in the near future. Characterize your model performance.

- To address this task, we look into two possible methods of predicting subscription cancellations: 
  - In the first method, we segment/cluster the customer base into groups based on their user activity. Using these segments, we predict whether a customer would move into a lesser active/likely to cancel group. 
  - In the second method, we classify our customer base on their recent subscription status to determine trends that can be used to predict the how much more likely a customer is to cancel their subscription.


#### First Method: predict whether a customer will cancel their subscription in the near future based on different segments customer

We will try to determine if we can segment the customers into buckets and determine 
if any behaviour related to their average online time, completed orders can be used to 
predict whether a customer will cancel their subscription in the near future

- First pass analysis of the predictors that would be used via Clustering and then assosiate the
users into the appropriate segments:
  - `Active`  - Customers who are actively using the website and likely to keep subscribing
  - `Napping` - Customers who are mostly active but have a few days of almost 0 activity. They are unlikely to cancel their subscription in the near future
  - `Sleepin` - Customers who are not very active and are more likely to leave the subscription in the coming months
  - `Cancelled` - Customers who have cancelled and will cancel for sure.
 
- Dataset used : `customer.overall.means`

- We first use K-Means to try to cluster our user base.

```{r}
std.customer <- na.omit(customer.overall.means) # listwise deletion of missing
std.customer <- scale(std.customer) # standardize variables
wss <- (nrow(std.customer)-1)*sum(apply(std.customer,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(std.customer,
   centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
km.res <- kmeans(std.customer, 4, nstart = 25)
str(km.res)
#clusplot(std.customer, km.res$cluster, color=TRUE, shade=TRUE,
#   labels=2, lines=0)
fviz_cluster(km.res, data = std.customer)
```
 
 - K-Means seems to be very crowded and not very interpretatble. Let us try Heirarchical Clustering

```{r}

set.seed(30)
#Heirarchical Clustering
# we create a 100% data partition from the subset of customers who cancelled
cancelled.customers = createDataPartition(customer.overall.means$id[which(customer.overall.means$lastStatus == 2)],l=F, p = 1)
# we create a 100% data partition from the subset of customers who are active
active.customers = createDataPartition(customer.overall.means$id[which(customer.overall.means$lastStatus == 1)],l=F, p = 1)

customer.train <- rbind(active.customers, cancelled.customers)

#The set is all the customers
scalled.customer = scale(customer.overall.means[,-1])
segmented.customers = customer.overall.means[customer.train,-1 ]
scalled.customer.train  = scalled.customer[customer.train, ]

# Compute distance metrics on the standardized customer data
distanceMatrix = dist(scalled.customer.train)

# Perform hierarchical clustering on distance metrics
hierarchical.cluster <- hclust(distanceMatrix, method = 'ward.D2')
# Build dendrogram object from hierarchical.cluster results
hierarchical.dendogram <- as.dendrogram(hierarchical.cluster)
# Extract the data (for rectangular lines)
hierarchical.dendogram <- dendro_data(hierarchical.dendogram, type = "rectangle")

names(hierarchical.dendogram)
head(hierarchical.dendogram$labels)

# Plot the dendogram
p <- ggplot(hierarchical.dendogram$segments) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend))+
  geom_text(data = hierarchical.dendogram$labels, aes(x, y, label = label),
            hjust = 1, angle = 90, size = 3)+
  ylim(-3, 15)+ ggtitle("Dendogram for Customer Segmentation")
print(p)
```

- The dendogram is too crowded and so we first try 5 segments and view the data

```{r}
members = cutree(hierarchical.cluster, k = 5)
aggregate(segmented.customers, by = list(members), mean)
```

 - We can try to understand the profile of each segment.
 - Customer falling under segment/group2 2 and 4 are likely to have left or leave the subscription (in a month or two). The number of pages visited on average is the least (for group 4) and their life span is large. These are customers who most likely got bored or found other resources. The latter ratio of last month to prev seems to have increased by almost 100% when comapred to the last to first month ratio. 
 - Similarly, we see how customers belonging to the segment/group 1 have an average status towards 2. Their last month to first month login ratio as well as the prev to last month ratio is the highest. We can say that customers that come under this segment are eventually likely to unscribe from the e-card greeting subscription. 

- Let us try decreasing the segments to 4 to see if more distinct status based segments can be obtained 

```{r}
# decreasing the segments to 4
members = cutree(hierarchical.cluster, k = 4)
segmented.customers.df <- as.data.frame(aggregate(segmented.customers, by = list(members), mean))
segmented.customers.df <- segmented.customers.df %>% dplyr::rename(Type = Group.1)
segmented.customers.df$Type <- c("Sleeping", "Cancelled", "Active", "Napping" )
segmented.customers.df
```

- We are able to see 4 disticnt groups and hence segregate the users into one of the categories - `Sleeping`, `Cancelled`, `Napping` and `Active`. We assign these categories to the respective users.
 - In general we notice that as the lifespan increases many customers tend to stop/cancel the subscription. This is alarming to the company as it is clear that more effort must be maintained in retaining current subscribers. A clear indication that customers would leave based on increasing lifespan is the difference between the two ratios. Larger the lastToPrevLogin ratio compared to the lastToFirst the more likely that the customer would stop the subscription. 
 - However, we notice that customers are more likely to stay on, even if their lifespan on average is large, if their browsing ratios are maintained within a 50% to 80% range.

- With the help of the clustered groups, we assign users into their respective segments.
  - 1 : `Sleeping`
  - 2 : `Cancelled`
  - 3 : `Active`
  - 4 : `Napping`  

```{r}
#Our train set contains all 10,000 users
segmented.customers$segment <- members

#Summary of the customer segmentation data set 
kable(summary(segmented.customers), digits = c(3, 3, 3, 3), format = "markdown")
```
 
##### QQ plot visualization
We now construct the data to draw the QQ plot to examine the performance of our groupings.

```{r}
#aggregate the dta
aggregate_customer <- segmented.customers
aggregate_customer$segment.label <- ifelse(aggregate_customer$segment == 1,'sleeping',ifelse(aggregate_customer$segment == 2,'Cancelled',ifelse(aggregate_customer$segment == 3,'Active','Napping')
))
aggregate_customer$status.label <- ifelse(aggregate_customer$lastStatus == 1,'Active User','Non-Active User')

```

Compare the distribution of the original status and the clustering segment. 
We want to see the differences of order completed based on their quantile distribution.

```{r}
# calculate the normal theoretical quantiles per group
df1 <- ddply(.data = aggregate_customer, .variables = .(status.label,segment.label), function(dat){
             q <- qqnorm(dat$completed, plot = FALSE)
             dat$xq <- q$x
             dat
}
)

# plot the sample values against the theoretical quantiles
ggplot(data = df1, aes(x = xq, y = completed)) +
  geom_point() +
  labs(title = 'QQ plots', x = 'Normal Quantiles', y = 'Data Completed Quantiles')+
  facet_grid(status.label ~ segment.label)
```

```{r}
#normalize the lifespan
# standardize the birth weights
aggregate_customer = mutate(aggregate_customer, 
                 lifespan.norm = (lifespan - min(lifespan,na.rm = TRUE))/
                   (max(lifespan,na.rm = TRUE) - min(lifespan,na.rm = TRUE)))

```

```{r}
# calculate the normal theoretical quantiles per group
df2 <- ddply(.data = aggregate_customer, .variables = .(status.label,segment.label), function(dat){
             q <- qqnorm(dat$lifespan.norm, plot = FALSE)
             dat$xq <- q$x
             dat
}
)

# plot the sample values against the theoretical quantiles
ggplot(data = df2, aes(x = xq, y = lifespan.norm)) +
  geom_point() +  
  labs(title = 'QQ plots', x = 'Normal Quantiles', y = 'lifespan Quantiles')+
  facet_grid(status.label ~ segment.label)
```

- In general, we can notice that there are no data fall in [Cancelled - Acive User] pair and [Active - Non-Active User] pair, which means our clustering performance is great based of the observation of the quantile plot.
On the one hand, it is interesting to metion the distribution of Napping and Sleeping user by Active user is quite similar in the first QQ plot. However, it changes a lot in the second QQ plot. It means we can assume that the customer performance of napping and sleeping user is similar. However, their lifetime is totolly different, the lifespan for napping user would be predictable while sleeping user is quite hard to predict.
On the other hand, in term of the [napping-Non-Active User pair], we can observe the distribution of them all fall in the first harf quantails. which means the size and them is quite small and distribution looks quite wield. It makes sense to us, because if the original user labeled as non-active user, it should not be labeled as napping user. However, for these small case misclassfication, we can tolerant it.
- In brief, the QQ plot examine our clustering model performance is very good.


- Using 70% of the `segmented.customers` dataset (with the users segmented into their groups) for training and the remaining 30% as the test set, we run the random forest and  SVM function with our output variable as `segment`.

##### Predicting via Random Forest

```{r, cache=TRUE}

set.seed(1)
# we create a 70:30 data partition from the subset of customers
train.segments = sample(1:nrow(segmented.customers), nrow(segmented.customers)*2/3)

customer.segements.train <- segmented.customers[train.segments, -4]
customer.segements.test <- segmented.customers[-train.segments, -4]

# Random Forest 
customer.segements.rf <- randomForest(as.factor(customer.segements.train$segment) ~ . ,data=customer.segements.train, importance=TRUE, ntree=150)
customer.segements.rf 
#plotting the importance of the variables in the model
varImpPlot(customer.segements.rf)

#creating a model to predict the segments that would move into cancellled 
customer.segements.rf.predict <- predict(customer.segements.rf, customer.segements.test)
customer.segements.rf.table <- table(customer.segements.rf.predict, customer.segements.test$segment)
customer.segements.rf.table

# display the measurement of confusion martixs
classMetrics(customer.segements.rf.table)
```

- We see an accuracy of 85.6% is obtained by using Random Forests to predict if a customer would leave the subscription. 

##### Predicting using SVM 

```{r}
#Creating the model
customer.segements.svm <-svm(as.factor(customer.segements.train$segment) ~ . , data = customer.segements.train)
customer.segements.svm
#We now develop the predict model given the svm model
customer.segements.svm.pred <- predict(customer.segements.svm, customer.segements.test)
#Confusion matric for the same
conf.mat.segments.svm<-table(customer.segements.svm.pred, customer.segements.test$segment)
conf.mat.segments.svm

# display the measurement of confusion martixs
classMetrics(conf.mat.segments.svm)
```

- SVM provides an accuracy of approximately 74% for the same.
- Hence we conclude that Random forests have a better performance in predicting if a customer will cancel their subscription in the near future based on different segments customer.

```{r, fig.height = 5, fig.width = 5}
# Plot the performance of each model
roc.Class1.rf <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.rf.predict))
rs <- roc.Class1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Cluster-Classification ROC")
roc.Class1.svm <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.svm.pred))
rs <- roc.Class1.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","SVM","SVM Best"), col = c("red","green","blue"),
       lty = c(2,3,3), pch = c(-1, -1, -1))
```

- The above plot shows the ROC curves for the Random Forest (in red) and the SVM (in green).
From the graph, we see that both Random Forests and SVM have almost similar sensitivity (true positive rate), with SVM very minutely varying at the beginning of the sensitivity-specificity threshold. 

#### Second Method: Classification on customer status based on statistical features 

- Before developing the model, we first create a `customer.classify` dataset, that contains the statistical features (mean, median, standard deviation and skewness) and corresponding ratios for each customer as described below:

|      Data Field       | Description                                                                         | 
|-----------------------|-------------------------------------------------------------------------------------|
|     `id`              | The unique identifier of the customer                                               |
|     `date`            | The unique identifier of the customer                                               |
|     `status`          | The final status of the customer taken from the `customer.lifespan` dataset.        |
|     `pages`           | The total number of pages visited by each customer.                                 |
|     `onsite`          | The total number of minutes spent on the site by each customer.                     |
|     `entered`         | The total number of sender entered orders by each customer.                         |
|     `completed`       | The total number of completed orders by each customer.                              |
|     `holiday`         | The total number of holiday orders by each customer.                                |
|     `gender`          | User gender ‘M’- male, ‘F’- female.                                                 |
|     `avgOnsite`       | The average number of minutes spent on the site by each customer.                   |
|     `medOnsite`       | The median of minutes spent on the site by each customer.                           |
|     `sdOnsite`        | The standard deviation of minutes spent on the site by each customer.               |
|     `skewOnsite`      | The skewness in minutes spent on the site by each customer.                         |
|     `avgPages`        | The average number of pages visited by each customer.                               |
|     `medPages`        | The median of pages visited by each customer.                                       |
|     `sdPages`         | The standard deviation of pages visited by each customer.                           |
|     `skewPages`       | The skewness of pages visited by each customer.                                     |
|     `avgEntered`      | The average number of sender entered ecards by each customer.                       |
|     `avgCompleted`    | The average number of completed orders by each customer.                            |
|     `avgHoliday`      | The average number of holiday orders by each customer.                              |
|     `enterPerPage`    | The average of entered by pages for each customer.                                  |
|     `completePerEnter`| The ratio of total completed orders to entered for each customer.                   |
|     `onsitePerEnter`  | The ratio of total onsite visits to entered ecards for each customer.               |
|     `onsitePerPage`   | The average of onsite visits by pages for each customer.                            |
|     `pagesPerHoliday` | The average of holidays orders by pages for each customer.                          |
|     `onsitePerHoliday`| The average of onsite visits by pages for each customer.                            |
|  `LastMonthOnsiteTime`| The onsite time in minutes for the last month visit by the customer.                |
| `LastMonthPagesViewed`| The number of pages visited in the last month by each customer.                     |
|-----------------------|-------------------------------------------------------------------------------------|


```{r}
#group the selected columns based on the customer ID
customer.classify <- customer.data[, c("id", "date", "status", "pages", "onsite", "entered", "completed", "holiday", "gender")] %>% group_by(id)
#add to the data set, statistical features - mean, median, standard deviation and skewness
customer.classify <-customer.classify %>% dplyr::mutate(avgOnsite = mean(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(medOnsite = median(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(sdOnsite = sd(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(skewOnsite = skewness(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(avgPages = mean(pages))
customer.classify <-customer.classify %>% dplyr::mutate(medPages = median(pages))
customer.classify <-customer.classify %>% dplyr::mutate(sdPages = sd(pages))
customer.classify <-customer.classify %>% dplyr::mutate(skewPages = skewness(pages))
customer.classify <-customer.classify %>% dplyr::mutate(avgEntered = mean(entered))
customer.classify <-customer.classify %>% dplyr::mutate(avgCompleted = mean(completed))
customer.classify <-customer.classify %>% dplyr::mutate(avgHoliday = mean(holiday))
customer.classify<-customer.classify %>% dplyr::mutate(enterPerPage = mean(entered/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% dplyr::mutate(completePerEnter = sum(completed)/sum(entered))
customer.classify<-customer.classify %>% dplyr::mutate(onsitePerEnter = sum(onsite)/sum(entered))
customer.classify<-customer.classify %>% dplyr::mutate(onsitePerPage = mean(onsite/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% dplyr::mutate(pagesPerHoliday = mean(holiday/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% dplyr::mutate(onsitePerHoliday = mean(holiday/onsite, na.rm = TRUE))
customer.classify <-customer.classify %>% dplyr::mutate(LastMonthOnsiteTime = tail(onsite, n=2)[1])
customer.classify <-customer.classify %>% dplyr::mutate(LastMonthPagesViewed = tail(pages, n=2)[1])

#Ensure the set only contains distinct values for ID
customer.classify <- customer.classify %>% dplyr::distinct(id, .keep_all = TRUE)

#add in the below columns from the aggregatedCustomerSums dataset
customer.classify <- transform(
  customer.classify,
  status = aggregatedCustomerSums$status,
  pages = aggregatedCustomerSums$pages,
  onsite = aggregatedCustomerSums$onsite,
  entered = aggregatedCustomerSums$entered,
  completed = aggregatedCustomerSums$completed,
  holiday = aggregatedCustomerSums$holiday
)

customer.classify<-transform(
  customer.classify,
  status = as.factor(status)
)

#Summary of the customer classification pre-processed data set  
kable(summary(customer.classify), digits = c(3, 3, 3, 3), format = "markdown")

```

We need to drop the `id` and `date` columns from the `customer.classify` dataset since we using these predictors will result in an incorrect model for our task.

```{r}
customer.classify.drop <- c("id","date")
customer.classify <- customer.classify[,!(names(customer.classify) %in% customer.classify.drop)]
```

Now we define the training and test dataset, with the training data set containing 70% of the data and the test set 30%

```{r}
# Classification method for task 1
# Define training set
set.seed(42)
classify.train<-sample(1:nrow(customer.classify), nrow(customer.classify)*2/3)
customer.classify.train <- customer.classify[classify.train,]
customer.classify.test <- customer.classify[-classify.train,]
```

We build 4 models using Logistic Regression, Random Forests, Naive Bayes and SVM to predict if a customer would cancel their subscription or not. All these models use `status` as their output variable with all other variables acting as predictors.

##### Predicting using Logistic Regression

```{r,cache = TRUE}
#create the logistic regression model and use the model for predicting using the test set
customer.classify.logit <- glm(as.factor(status)~., data = customer.classify.train, family="binomial")
customer.classify.logit.probs <- predict(customer.classify.logit, customer.classify.test, type="response")
summary(customer.classify.logit)

#Using alpha as 0.5, classify predictions as 2 if the values are above 0.5
customer.classify.logit.pred = rep("1",nrow(customer.classify.test))
customer.classify.logit.pred[customer.classify.logit.probs>0.5] = "2"

#Display the confusion matrix
customer.classify.logit.table <- table(customer.classify.logit.pred, customer.classify.test$status)
customer.classify.logit.table

# display the measurement of confusion martixs
classMetrics(customer.classify.logit.table)
```
- The logistic regression has an accuracy of 83.53%. This is a good classification.

##### Predicting using Random Forest

```{r,cache = TRUE}
# build the random forest model for classification
customer.classify.rf <- randomForest(status~., data=customer.classify.train, ntree=500, proximity=T,na.action = na.roughfix)
customer.classify.rf
customer.classify.rf.predict <- predict(customer.classify.rf, customer.classify.test)
customer.classify.rf.table <- table(customer.classify.rf.predict, customer.classify.test$status)
customer.classify.rf.table

# display the measurement of confusion martixs
classMetrics(customer.classify.rf.table)
```

- The random forest model provides an accuracy of 80.32%. It does not perform as well as the Logistic Regression.

##### Predicting using Naive Bayes

```{r}
# build the naive bayes model
customer.classify.nb <-naiveBayes(status ~., data = customer.classify.train, laplace=1)
summary(customer.classify.nb)
customer.classify.nb.pred <- predict(customer.classify.nb, customer.classify.test)

customer.classify.nb.table<-table(customer.classify.nb.pred, customer.classify.test$status)
customer.classify.nb.table

# display the measurement of confusion martixs
classMetrics(customer.classify.nb.table)
```

- Accuracy attained using Naive Bayes is 68.62%. It it considerably low when compared to Random Forests and Naive Bayes.

##### Predicting using SVM

```{r}
# create the SVM model
customer.classify.svm <-svm(status~ . , data = customer.classify.train, type = 'C-classification', kernel = 'radial')
customer.classify.svm.pred <- predict(customer.classify.svm, customer.classify.test)

customer.classify.svm.table<-table(customer.classify.svm.pred, customer.classify.test$status)
customer.classify.svm.table

# display the measurement of confusion martixs
classMetrics(customer.classify.svm.table)
```

- SVM appears to be the best model with an accuracy of 83.98% and overall metrics, with the logistic regression model following closely behind.

```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Class2.rf <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.rf.predict))
rs <- roc.Class2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Direct Classification ROC")
roc.Class2.logit <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.logit.pred))
rs <- roc.Class2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Class2.nb <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.nb.pred))
rs <- roc.Class2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Class2.svm <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.svm.pred))
rs <- roc.Class2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","Logistic Regression","Naive Bayes","SVM"), col = c("red","black","blue","green"),
       lty = c(2,3,3,3), pch = c(-1, -1, -1, -1))
```

- The above plot shows the ROC curves for the Random Forest (in red), Logistic Regression (in black), Naive Bayes (in blue) and the SVM (in green).
From the graph, we see that both Logistic Regression and SVM have almost similar sensitivity (true positive rate), with SVM very minutely having a higher sensitivity-specificity threshold with higher sensitivity/specificity. As specificity increases Random forests also meet the same level of sensitivity as Logistic Regression and SVM. 


## 2. Develop a model for estimating the ltv of a customer. Characterize your model performance.

We use the `aggregatedCustomerSums` dataset with the addition of the `lifespan` in terms of months. This new term is called the `lifespanByMonth`. 
From this new dataset called the `aggregatedCustomerSumsTask2`, we drop predictors that will not help with the model performance as shown in the below code.

```{r}
aggregatedCustomerSumsTask2 <- transform(
  aggregatedCustomerSums,
  lifespanByMonth = ceiling(lifespan/30)
)

aggregatedCustomerSumsTask2.drop <- c("id","status","gender","lifespan","decisiveratio","holiday.ratio","holiday.user")
aggregatedCustomerSumsTask2 <- aggregatedCustomerSumsTask2[,!(names(aggregatedCustomerSumsTask2) %in% aggregatedCustomerSumsTask2.drop)]
```

Using this, we now cluster the data into 3 LTV groups Low, Medium and High via K-Means.

```{r}
set.seed(42)
#K-means Clustering
aggregatedCustomerSumsTask2 <- na.omit(aggregatedCustomerSumsTask2) # listwise deletion of missing
std.aggregatedCustomerSumsTask2 <- rescale(data.matrix(aggregatedCustomerSumsTask2)) # standardize variables
wss <- (nrow(std.aggregatedCustomerSumsTask2)-1)*sum(apply(std.aggregatedCustomerSumsTask2,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(std.aggregatedCustomerSumsTask2,
   centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
km.ltv <- kmeans(std.aggregatedCustomerSumsTask2, 3, nstart = 25)
str(km.ltv)
fviz_cluster(km.ltv, data = std.aggregatedCustomerSumsTask2)
```
- Using these new groupings, a new dataset called `clustered.ltv` is created with the following columns:



```{r}

clustered.ltv <- data.frame(km.ltv$centers)
clustered.ltv <- data.frame(Type = c("Medium LTV", "High LTV", "Low LTV"),clustered.ltv)
clustered.ltv <- transform (
  clustered.ltv,
  pages = pages * max(aggregatedCustomerSumsTask2),
  onsite = onsite * max(aggregatedCustomerSumsTask2),
  entered = entered * max(aggregatedCustomerSumsTask2),
  completed = completed * max(aggregatedCustomerSumsTask2),
  lifespanByMonth = lifespanByMonth * max(aggregatedCustomerSumsTask2)
)

clustered.ltv$lifetimeValue = clustered.ltv$lifespanByMonth * 1
clustered.ltv

```

- Since predicting “specific” lifetime value might not generate much business value, we would like to segment our customers into three groups: High LTV group, Medium LTV group and Low LTV group.  By segmenting our customers into three groups, we can design different business plans for different groups. 
- The LTV per customer is customer lifespan(in month) * the monthly subscription fee($1). We are using this formula to estimate the customer lifetime value and therefore generate a customer clustering based upon it.
- After doing K-means clustering, we can see that High LTV group generates LTV two times larger than that of the Low LTV group. Thus, we should focus more on the High LTV group later when we are promoting.


## 3.	Develop a customer segmentation scheme. Include in this scheme the identification of sleeping customers, those that are no longer active but have not canceled their account.

- There are multiple ways we can segment the customers. For this task we look into two possible ways of doing so: 
  - In the first segmentation, we group the customer base into Regularly active, Sleeping and Inactive customers. We also try to understand the possibility of groups based on Holiday vs Non-Holiday users. 
  - In the second segmentation, we group customers based on their decisiveness in placing orders i.e. Decisive, Tentative and Hesitant customers.

#### Segmentation 1: Regular(users who have completed regularly irrespective of holidays), Sleeping, Inactive (canceled); Holiday User and Non Holiday use 
 

- In this section, the holiday user label depends on the proportion of the aggregrated sum of orders which completed in holiday, we treat the quantile distribution which larger than the third quantaile as the holiday user.

```{r}
aggregatedCustomerSums$holiday.ratio <- aggregatedCustomerSums$holiday/aggregatedCustomerSums$completed
summary(aggregatedCustomerSums$holiday.ratio)
aggregatedCustomerSums$holiday.user <- ifelse(aggregatedCustomerSums$holiday.ratio>0.4573,1,0)
```


- Variables: Completed, pages, onsite, entered
- Classification label: Regular/Sleeping/Inactive
  - 3: if the customer has status as 2 or if they have not visited the website on the given date, then customer is inactive.
  - 2: if the customer has browsed the website >60 days of `12/31/2014` then classify the customer as sleeping.
  - 1: if the customer has recently browsed the website has been active within 60 days of `12/31/2014` then classify the customer as active.


```{r}
width = length(customer.data)
len = length(customer.data$id)
user.type = rep(0, times = len)
previd = customer.data[1][1]
startid = previd
for(i in seq(len)){
  startid = customer.data[i,1]
  if(customer.data[i,2] == 2){
    user.type[i] = 3
  }else if(startid!=previd){
    diff = (as.Date('12/31/2014','%m/%d/%Y') - customer.data[i-1,4])
    if(diff>60){
      user.type[i-1] = 2
      user.type[i] = 1
    }else{
      user.type[i] = 1
    }
  }else{
    user.type[i] = 1
  }
  previd = startid
}
customer.data$userType <- user.type
```

From the `customer.data` dataset, we pick the below for our model.

|      Data Field       | Description                                                                         | 
|-----------------------|-------------------------------------------------------------------------------------|
|     `pages`           | The overall average number of pages visited by the customer.                        |
|     `onsite`          | The overall average number of minutes spent on the site by the customer.            |
|     `userType`        | The user type which belong to the cluster number 1,2 and 3                          |

```{r}
#select the data we need, we do not want to overfit the model, and hence will only include all the data. 
# maxDate related data for the each user.
customer.data.segOne <- customer.data %>% group_by(id) %>% filter(date == max(date)) 
customer.data.segOne <- subset(customer.data.segOne,select = c('pages','onsite', 'userType'))

#split into training and test dataset
customer.data.segOne <- transform(
  customer.data.segOne,
  pages=as.integer(pages),
  onsite=as.integer(onsite),
  userType = as.factor(userType)
)

#Summary of the customer classification for differnet user type  
kable(summary(customer.data.segOne), digits = c(3, 3, 3, 3), format = "markdown")

set.seed(1)
dt = sort(sample(nrow(customer.data.segOne), nrow(customer.data.segOne)*.7))
train.segOne<-customer.data.segOne[dt,]
test.segOne<-customer.data.segOne[-dt,]
```

-- In this section, we would use different classfication models to predict the user type based on the total page number and total onsite minutes. The result will be analyzed by confusion matrix and several classifer performance metrics.

##### Predicting using Random Forest
```{r}
customer.segOne.rf <- randomForest(
  as.factor(userType) ~ ., 
  data = train.segOne, 
  importance = TRUE,
  num.trees = 500
)

customer.segOne.rf

varImpPlot(customer.segOne.rf)

customer.segOne.pred <- predict(customer.segOne.rf, test.segOne)
customer.segOne.rfResult<- table(test.segOne$userType, customer.segOne.pred)
customer.segOne.rfResult

# display the measurement of confusion martixs
classMetrics(customer.segOne.rfResult)
```


##### Predicting using Logistic Regression

```{r}
#create the logistic regression model with output as userType and inputs as pages, onsite, entered and completed.
customer.segOne.lr <- multinom(train.segOne$userType ~ . , data = train.segOne)
customer.segOne.lr
#test the model classification on the test data
customer.segOne.lr.pred <- predict(customer.segOne.lr,newdata=test.segOne)
#create a confusion matrix
customer.segOne.lr.conf <-table(customer.segOne.lr.pred, test.segOne$userType)
prop.table(customer.segOne.lr.conf)

# display the measurement of confusion martixs
classMetrics(customer.segOne.lr.conf)
```

##### Predicting using Naive Bayes

```{r}
#Construct a naive bayes classification model on the train data set
customer.segOne.nb <-naiveBayes(train.segOne$userType ~ ., data = train.segOne)
customer.segOne.nb
#test the model classification on the test data
customer.segOne.nb.pred <- predict(customer.segOne.nb, newdata=test.segOne)
#create a confusion matrix
customer.segOne.nb.conf <-table(customer.segOne.nb.pred, test.segOne$userType)
prop.table(customer.segOne.nb.conf)

# display the measurement of confusion martixs
classMetrics(customer.segOne.nb.conf)
```

- Based on the observation of the models of Random Forest, Logistic Regression, Naive Bayes, we can found that Random Forest has the best performance.


-- Visualize the ROC graph

```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Seg1.rf <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.pred))
rs <- roc.Seg1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 1 ROC")
roc.Seg1.logit <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.lr.pred))
rs <- roc.Seg1.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg1.nb <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.nb.pred))
rs <- roc.Seg1.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","Logistic Regression","Naive Bayes"), col = c("red","black","blue"),
       lty = c(2,3,3), pch = c(-1, -1, -1))
```

- The above plot shows the ROC curves for the Random Forest (in red), Logistic Regression (in black), Naive Bayes (in blue).
From the graph, we see that both Logistic Regression and Random Forest have almost similar sensitivity (true positive rate), with Naive Bayes very minutely having a higher sensitivity-specificity threshold with higher sensitivity/specificity. As specificity increases Naive Bayes also meet the same level of sensitivity as Logistic Regression and Random Forest.


#### Segmentation 2: Decisive customers, Tentative customers, Hesitant customers

- Variables: Gender, onsite, pages, entered, completed
- Classification label: completed / entered 
  - 2: if the `decisiveratio` of that customer is greater or equal to `r summary(aggregatedCustomerSums$decisiveratio)[5]` then we classfy the customer as decisive
  - 1: if the `decisiveratio` of that customer fall in the range of `r summary(aggregatedCustomerSums$decisiveratio)[2]` and `r summary(aggregatedCustomerSums$decisiveratio)[5]`, then we classfy the customer as tentative
  - 0: if the `decisiveratio` of that customer is smaller than `r summary(aggregatedCustomerSums$decisiveratio)[2]` , then we classfy the customer as hesitant

```{r}
summary(aggregatedCustomerSums$decisiveratio)
```


|      Data Field       | Description                                                                         | 
|-----------------------|-------------------------------------------------------------------------------------|
|     `pages`           | The overall average number of pages visited by the customer.                        |
|     `onsite`          | The overall average number of minutes spent on the site by the customer.            |
|     `userType`        | The user type which belong to the cluster number 1,2 and 3                          |
|     `holiday`         | The total number of holiday orders by the customer.                                 |
|     `gender`          | User gender ‘M’- male, ‘F’- female.                                                 |
|     `lifespan`        | The lifespan of the customer taken from the `customer.lifespan` dataset.            | 
|     `deisivelabel`    | we define customer has three types -- decisive, tentative and hesitant and label    |
|                       | them as 2, 1 and 0 repspectively                                                    |
|-----------------------|-------------------------------------------------------------------------------------|

```{r}
# create data labels 
decisivelabel <- with(aggregatedCustomerSums, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[5], 2, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[2],1,0)))
# merge the created label with selected data
decisive.data <- data.frame(aggregatedCustomerSums[c("pages", "onsite","holiday","gender","lifespan")], decisivelabel = as.factor(decisivelabel))
set.seed(42)
# separate data into train, test data
#randomly get 2/3 data of each label into train data, 1/3 data of each label into test data
hesitant<-subset(decisive.data, decisivelabel == 0)
tentative<-subset(decisive.data, decisivelabel == 1)
decisive<-subset(decisive.data, decisivelabel == 2)
train.h<-hesitant[sample(nrow(hesitant),), ][c(1:1658), ]
test.h<-hesitant[sample(nrow(hesitant),), ][c(1659:2487), ]
train.t<-tentative[sample(nrow(tentative),), ][c(1:3155),]
test.t<-tentative[sample(nrow(tentative),), ][c(3156:4732),]
train.d<-decisive[sample(nrow(decisive),), ][c(1:1854),]
test.d<-decisive[sample(nrow(decisive),), ][c(1854:2781),]
decisive.train<-rbind(train.h, train.t, train.d)
decisive.test<-rbind(test.h, test.t, test.d)
```

-- In this section, we would use five classfication models to predict the customer decisive label based on several features -- pages, onsite, userType, holiday, gender, lifespan and deisivelabel. The result will be analyzed by confusion matrix and several classifer performance metrics.

##### Predicting using Random Forest

```{r, cache = TRUE}
# build the random forest model for classification
customer.rf <- randomForest(decisivelabel~., data=decisive.train, ntree=500, proximity=T)
customer.rf
customer.rf.predict <- predict(customer.rf, decisive.test)
customer.rf.table <- table(customer.rf.predict, decisive.test$decisivelabel)
customer.rf.table

# display the measurement of confusion martixs
classMetrics(customer.rf.table)
```

##### Predicting using KNN

```{r}
train_control <- trainControl(method = "cv", number = 10)
customer.knn <- train(decisivelabel~., data = decisive.train, trControl = train_control, method = "knn")
customer.knn
customer.knn.predict <- predict(customer.knn, decisive.test)
customer.knn.table <- table(customer.knn.predict, decisive.test$decisivelabel)
customer.knn.table

# display the measurement of confusion martixs
classMetrics(customer.knn.table)
```

##### Predicting using Mulrinomial Logistic Regression

```{r}
decisve.ml <- multinom(decisivelabel ~ . , data = decisive.train)
decisve.ml
logit.pred <- decisve.ml %>% predict(decisive.test)
conf.mat.logit<-table(logit.pred, decisive.test$decisivelabel)
conf.mat.logit

# display the measurement of confusion martixs
classMetrics(conf.mat.logit)
```

##### Predicting using Naive Bayes

```{r}
decisive.nb <-naiveBayes(decisivelabel ~ . , data = decisive.train, laplace=1)
decisive.nb.pred <- predict(decisive.nb, decisive.test)
conf.mat.nb<-table(decisive.nb.pred, decisive.test$decisivelabel)
conf.mat.nb

# display the measurement of confusion martixs
classMetrics(conf.mat.nb)
```

##### Predicting using SVM

```{r}
decisive.svm <-svm(decisivelabel ~ . , data = decisive.train, type = 'C-classification', kernel = 'radial')
decisive.svm.pred <- predict(decisive.svm, decisive.test)
conf.mat.svm<-table(decisive.svm.pred, decisive.test$decisivelabel)
conf.mat.svm

# display the measurement of confusion martixs
classMetrics(conf.mat.svm)
```

-- Based on the observation of the models of Random Forest, KNN, Mulrinomial Logistic Regression, Naive Bayes and SVM, we can found that Random Forest has the best performance.

```{r, fig.height = 5, fig.width = 5}
# Plotthe performance of each model
roc.Seg2.rf <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.rf.predict))
rs <- roc.Seg2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 2 ROC")
roc.Seg2.knn <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.knn.predict))
rs <- roc.Seg2.knn[['rocs']]
plot(rs[[1]], col = "steelblue", lty = 3, add = TRUE)
roc.Seg2.logit <- multiclass.roc(decisive.test$decisivelabel, as.numeric(logit.pred))
rs <- roc.Seg2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg2.nb <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.nb.pred))
rs <- roc.Seg2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Seg2.svm <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.svm.pred))
rs <- roc.Seg2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","KNN","Logistic Regression","Naive Bayes","SVM"), col = c("red","steelblue","black","blue","green"),
       lty = c(2,3,3,3,3), pch = c(-1, -1, -1, -1, -1))
```

- The above plot shows the ROC curves for the Random Forest (in red),KNN (in steelblue) Logistic Regression (in black), Naive Bayes (in blue) and SVM (in green).
From the graph, we see that only the performance of Random Forest looks acceptable.
---
title: "ltvProject"
author: "Blake Tian"
output: html_document
---


## R Markdown

Our client is an online greeting card company. The company offers monthly subscriptions at a rate of $1 per month for access to their eCard website. The client is interested in understanding the life-time value (ltv) of their customers.
The life-time value of a customer is defined as the total revenue earned by the company over the course of their relationship with the customer.
The enclosed (synthetic) data represent usage statistics for 10,000 customers. Usage is summarized at a daily level and covers a period of 4 years from 2011-01-01 to 2014-12-31.
The following is a description of each field captured in the enclosed data set containing a total of 10,000 customers.

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
| `id`       | A unique user identifier                                                            |
| `status`   | Subscription status ‘0’- new, ‘1’- open, ‘2’- cancelation event                     |
| `gender`   | User gender ‘M’- male, ‘F’- female                                                  |
| `date`     | Date of in which user ‘id’ logged into the site                                     |
| `pages`    | Number of pages visted by user ‘id’ on date ‘date’                                  |
| `onsite`   | Number of minutes spent on site by user ‘id’ on date ‘date’                         |
| `entered`  | Flag indicating whether or not user entered the send order path on date ‘date’      |
| `completed`| Flag indicating whether the user completed the order (sent an eCard)                |
| `holiday`  | Flag indicating whether at least one completed order included a holiday themed card |

We must preprocess the data to determine the following: 

| Data Field | Description                                                                         | 
|------------|-------------------------------------------------------------------------------------|
| `lifespan` | The lifespan of each customer in days, for cancelled customers= cancelDate-openDate,|
|            | for open customers=maxDate-openDate+1/(cancelled customers/total customers)         |


```{r, message=FALSE}
library(tidyverse)
library(ggplot2)
library(ISLR)
library(partykit)
library(caret)
library(rpart)
library(randomForest)
library(pROC)
library(readxl)
library(binaryLogic)
library(dplyr)
library(class)
library(DMwR)
library(nnet)
library(e1071)
library(ranger)
library(glmnet)
library(cluster)
library(ggdendro)

```

```{r, cache = TRUE}
# Importing the data directly from Excel
customer.data <- read_excel("C://Users//nelli//Downloads//ltv Dataset.xlsx", sheet = "Sheet1")
```

```{r, cache = TRUE}
# Transform the data to teh desired format
customer.data <- transform(
  customer.data,
  id=as.integer(id),
  status=as.integer(status),
  gender=as.factor(gender),
  date=as.Date(date),
  pages=as.integer(pages),
  onsite=as.integer(onsite),
  entered=as.integer(entered),
  completed=as.integer(completed),
  holiday=as.integer(holiday)
)
```

```{r}
#processing the date
customer.data$date <- as.Date(customer.data$date,'%m/%d/%Y')
customer.data$month <- months(customer.data$date)
customer.data$year <- format(customer.data$date,format = '%Y')
```

```{r}
#calculate the average value
ltv.pages <- aggregate( pages ~ id+ month + year, customer.data, mean)
ltv.onsite <- aggregate( onsite ~ id + month + year, customer.data, mean)

#merger the table
ltv.m1 <- merge(x = ltv.pages, y = ltv.onsite, by = c('id','month','year'), all.x = TRUE)

#find the overall login counts per month
ltv.logins <- aggregate(cbind(count = date) ~ id + month + year, 
          customer.data, 
          FUN = function(x){NROW(x)})
#order this by the id, year and month
ltv.logins <- ltv.logins[
  with(ltv.logins, order(id, year, match(ltv.logins$month, month.name))),]  %>% group_by(id)

```

```{r}
#sort the dataframe and export it
ltv.m1 <- ltv.m1[order(ltv.m1$id),]
ltv.m1
write.csv(ltv.m1,'ltv_modelOne.csv',row.names = FALSE)
```

```{r, cache=TRUE}
#convert the data from numeric to date type (duplicate) 
#customer.data$date <- as.Date(customer.data$date, origin = "1899-12-30")
#Calculate the customer lifespan 
#first group the data by ID to find the max and min date for a given customer
#along with the latest status 
customer.lifespan <- customer.data[, c("id", "date", "status")] %>% group_by(id)
customer.lifespan <-customer.lifespan %>% mutate(maxDate = max(date)) 
#we can asssume that a maxstatus of 0 => that the user just created the account and did not login 
#after, we will consider such a scenario as active
customer.lifespan <-customer.lifespan %>% mutate(status = ifelse(max(status)==0, 1,max(status))) 
customer.lifespan <- customer.lifespan %>% filter(date == min(date)) %>% distinct(id, .keep_all = TRUE) %>% rename(minDate = date)
#Subtract the maxDate and minDate to determine the number of days of subscription
customer.lifespan$subDays <- as.integer(difftime(customer.lifespan$maxDate, customer.lifespan$minDate, units = "days"))
#Determine the observed lifespan factor to be added
lifespanFraction <- 1/(with(1, sum(customer.data$status == 2))/10000)
#calculate the lifespan for the customers
customer.lifespan$lifespan <- customer.lifespan$subDays

#find the max and min Months and years
customer.lifespan$maxMonth <- months(customer.lifespan$maxDate)
customer.lifespan$minYear <- format(customer.lifespan$maxDate,format = '%Y')
customer.lifespan$minMonth <- months(customer.lifespan$minDate)
customer.lifespan$minYear <- format(customer.lifespan$minDate,format = '%Y')


#customer.lifespan$lifespan <- ifelse(customer.lifespan$status == 2, customer.lifespan$subDays, customer.lifespan$subDays + lifespanFraction)
#add this data to the main dataset 
customer.data$lifespan <- customer.lifespan$lifespan[match(customer.data$id,customer.lifespan$id)]


customer.overall.means <- aggregate(customer.data[, c("pages", "onsite", "completed")], list(customer.data$id), mean)
customer.overall.means <- customer.overall.means %>% rename(id = Group.1)
customer.overall.means$lastStatus <- customer.lifespan$status
customer.overall.means$lifespan <- customer.lifespan$lifespan
#determine the logins in the first month, last and the last but one 
customer.firstMonth.logins <- ltv.logins  %>%  filter(row_number()==1) %>% dplyr::select("id", "count")
customer.previousMonth.logins <- ltv.logins  %>%  filter(row_number()==n()-1) %>% dplyr::select("id",  "count")
customer.lastMonth.logins <- ltv.logins  %>%  filter(row_number()==n()) %>% dplyr::select("id", "count")

#determine the login ratios of lastMonth to first and the last month to the last but on
len = length(customer.overall.means$id)

for (i in seq(length(customer.overall.means$id))) {
  curId <- customer.overall.means$id[i]
  lastMonthLogins <- customer.lastMonth.logins[which(customer.lastMonth.logins$id==curId),2]
  firstMonthLogins <- customer.firstMonth.logins[which(customer.firstMonth.logins$id==curId),2]
  prevMonthLogins <- customer.previousMonth.logins[which(customer.previousMonth.logins$id==curId),2]
  if (is.na(prevMonthLogins$count[1])){
    #print(curId)
    prevMonthLogins <- lastMonthLogins
  }
  customer.overall.means$lastToFirstLoginRatio[i] <- as.numeric(lastMonthLogins/firstMonthLogins)
  customer.overall.means$lastToPrevLoginRatio[i] <- as.numeric(lastMonthLogins/prevMonthLogins)
}

```

Before using the predictors from the `customer.overall.means` table we must ensure that there is minimum co-relation between the terms. 

```{r}
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = pmax(1, cex.cor * r))
}

# Use panel.cor to display correlations in lower panel.
pairs(customer.overall.means[,c(-1)], lower.panel = panel.cor) 

```
- From the above plots, we see that most of the predictors have very low correlation among themselves. While `pages` and `completed` have a .76 correlation between them, we still consider both of them as part of the model as the value is not too high to imply complete correlation. Hence removing either could cause the model to miss out on certain insights.

```{r, cache = TRUE}
# Add 2 columns in the dataframe representing completed/holiday and onsite/entered
ltv_afterProcess <- transform(
  customer.data,
  CompletedVSHoliday=as.integer(entered)/as.integer(holiday),
  OnsiteVSEntered=as.integer(onsite)/as.integer(entered)
)
```

```{r, cache = TRUE}
# calculate the ratio between sum of all entered and sum of all completed
SumEnteredVSCompleted <- sum(ltv_afterProcess$entered)/sum(ltv_afterProcess$completed)
SumEnteredVSCompleted
```

```{r, cache = TRUE}
# create a new dataframe representing teh aggregated summation of each variable per customer
aggregatedCustomerSums <- aggregate(cbind(PagesSum=ltv_afterProcess$pages, OnsiteSum=ltv_afterProcess$onsite, EnteredSum=ltv_afterProcess$entered, CompletedSum=ltv_afterProcess$completed, HolidaySum=ltv_afterProcess$holiday), by=list(Customerid=ltv_afterProcess$id), FUN=sum)
aggregatedCustomerSums<-merge(x = aggregatedCustomerSums, y = customer.data, intersect(names(aggregatedCustomerSums), names(customer.data)), by.x = "Customerid", by.y = "id", all.x=TRUE)[,c(names(aggregatedCustomerSums), "gender")]%>% distinct(Customerid, .keep_all=TRUE)
aggregatedCustomerSums <- transform(
  aggregatedCustomerSums,
  gender = as.factor(gender),
  status = customer.lifespan$status,
  lifespan = customer.lifespan$lifespan,
  decisiveratio = CompletedSum / EnteredSum
)
aggregatedCustomerSums <- rename(aggregatedCustomerSums, id = Customerid, pages = PagesSum, onsite = OnsiteSum, entered = EnteredSum, completed = CompletedSum, holiday = HolidaySum)
```


## 1.	Develop an attrition model, to predict whether a customer will cancel their subscription in the near future. Characterize your model performance.

#First Method: predict whether a customer will cancel their subscription in the near future based on different segments customer

We will try to determine if we can segment the customers into buckets and determine 
if any behaviour related to their average online time, completed orders can be used to 
predict whether a customer will cancel their subscription in the near future

- First pass analysis of the predictors that would be used via Clustering and then assosiate the
users into the appropriate segments:
`Active`  - Customers who are actively using the website and likely to keep subscribing
`Napping` - Customers who are mostly active but have a few days of almost 0 activity. They are unlikely to cancel their subscription in the near future
`Sleepin` - Customers who are not very active and are more likely to leave the subscription in the coming months
`Cancelled` - Customers who have cancelled and will cancel for sure.
 

```{r}
std.customer <- na.omit(customer.overall.means) # listwise deletion of missing
std.customer <- scale(std.customer) # standardize variables
wss <- (nrow(std.customer)-1)*sum(apply(std.customer,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(std.customer,
   centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
  ylab="Within groups sum of squares")
km.res <- kmeans(std.customer, 4, nstart = 25)
str(km.res)
clusplot(std.customer, km.res$cluster, color=TRUE, shade=TRUE,
   labels=2, lines=0)
```
 - K-Means seems too crowded and not very interpretatble. Let us try Heirarchical Clustering

```{r}

set.seed(30)
#Heirarchical Clustering
# we create a 100% data partition from the subset of customers who cancelled
cancelled.customers = createDataPartition(customer.overall.means$id[which(customer.overall.means$lastStatus == 2)],l=F, p = 1)
# we create a 100% data partition from the subset of customers who are active
active.customers = createDataPartition(customer.overall.means$id[which(customer.overall.means$lastStatus == 1)],l=F, p = 1)

customer.train <- rbind(active.customers, cancelled.customers)

scalled.customer = scale(customer.overall.means[,-1])
cancelled.customers.train = customer.overall.means[customer.train,-1 ]
#cancelled.customers.test = customer.overall.means[-customer.train, -1]

scalled.customer.train  = scalled.customer[customer.train, ]
# Compute distance metrics on the standardized customer data
distanceMatrix = dist(scalled.customer.train)

# Perform hierarchical clustering on distance metrics
hierarchical.cluster <- hclust(distanceMatrix, method = 'ward.D2')
# Build dendrogram object from hierarchical.cluster results
hierarchical.dendogram <- as.dendrogram(hierarchical.cluster)
# Extract the data (for rectangular lines)
hierarchical.dendogram <- dendro_data(hierarchical.dendogram, type = "rectangle")

names(hierarchical.dendogram)
#head(hierarchical.dendogram$segments)
head(hierarchical.dendogram$labels)

# Plot the dendogram
p <- ggplot(hierarchical.dendogram$segments) + 
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend))+
  geom_text(data = hierarchical.dendogram$labels, aes(x, y, label = label),
            hjust = 1, angle = 90, size = 3)+
  ylim(-3, 15)+ ggtitle("Dendogram for Customer Segmentation")
print(p)
```
#The dendogram is too crowded and so we first try 5 segments and view the data

```{r}
members = cutree(hierarchical.cluster, k = 5)
aggregate(cancelled.customers.train, by = list(members), mean)
```
 - We can try to understand the profile of each segment.
 - Customer falling under segment/group2 2 and 4 are likely to have left or leave the subscription (in a month or two). The number of pages visited on average is the least and their life span is large. These are customers who most likely got bored or found other resources. The latter ratio of last month to prev seems to have increased by almost 100% when comapred to the last to first month ratio. 
 - Similarly, we see how customers belonging to the segment/group 1 have an average status towards 2. Their last month to first month login ratio as well as the prev to last month ratio is the highest. We can say that customers that come under this segment are likely to unscribe from the e-card greeting subscription. 

- Let us try decreasing the segments to 4 to see if more distinct status based segments can be obtained 
```{r}
# decreasing the segments to 4
members = cutree(hierarchical.cluster, k = 4)
segmented.customers <- as.data.frame(aggregate(cancelled.customers.train, by = list(members), mean))
segmented.customers <- segmented.customers %>% rename(Type = Group.1)
segmented.customers$Type <- c("Sleeping", "Cancelled", "Active", "Napping" )
segmented.customers
```
- We are able to see 4 disticnt groups and hence segregate the users into one of the categories - `Sleeping`, `Cancelled`, `Napping` and `Active`. We assign these categories to the respective users.

```{r}
cancelled.customers.train$segment <- members


View(cancelled.customers.train)

```
- With 4 segments we can see clearer segments forming with distinct behaviour.
 - In general we notice that as the lifespan increases customers tend to stop/cancel the subscription. This is alarming to the company as it is clear that more effort must be maintained in retaining current subscribers. A clear indication that customers would leave based on increasing lifespan is the difference between the two ratios. Larger the lastToPrevLogin ratio compared to the lastToFirst the more likely that the customer would stop the subscription. 
 - However, we notice that customers are more likely to stay on, even if their lifespan on average is large, if their browsing ratios are maintained within a 50% to 80% range.

# Predicting via SVM
```{r, cache=TRUE}

set.seed(1)
# we create a 70:30 data partition from the subset of customers
train.segments = sample(1:nrow(cancelled.customers.train), nrow(cancelled.customers.train)*2/3)

customer.segements.train <- cancelled.customers.train[train.segments, -4]
customer.segements.test <- cancelled.customers.train[-train.segments, -4]

# Random Forest 

customer.segements.rf <- randomForest(as.factor(customer.segements.train$segment) ~ . ,data=customer.segements.train, importance=TRUE, ntree=150)
customer.segements.rf 
#plotting the importance of the variables in the model
varImpPlot(customer.segements.rf)

#creating a model to predict the segments that would move into cancellled 
customer.segements.rf.predict <- predict(customer.segements.rf, customer.segements.test)
customer.segements.rf.table <- table(customer.segements.rf.predict, customer.segements.test$segment)
customer.segements.rf.table

# Determine accuracy of the model
customer.segements.rf.misclass = mean(customer.segements.rf.predict != customer.segements.test$segment)
1- customer.segements.rf.misclass

```
#SVM performance for the above

```{r}
#Creating the model
customer.segements.svm <-svm(as.factor(customer.segements.train$segment) ~ . , data = customer.segements.train)
customer.segements.svm
#We now develop the predict model given the svm model
customer.segements.svm.pred <- predict(customer.segements.svm, customer.segements.test)
#Confusion matric for the same
conf.mat.segments.svm<-table(customer.segements.svm.pred, customer.segements.test$segment)
conf.mat.segments.svm
#Determine the accuracy
conf.mat.segments.svm.accuracy<- sum(diag(conf.mat.segments.svm)) / sum(conf.mat.segments.svm)
conf.mat.segments.svm.accuracy
```
- The accuracy is only 73.99 %. Let us try tuning the model for better prediction rates

```{r, cache=TRUE, eval=FALSE}
#Parameter tuning - takes 30 minutes almost 
customer.seg.svm.tuned <-tune.svm(customer.segements.train, as.factor(customer.segements.train$segment), gamma=c(0.1, 1, 10), cost=10^(-1:2))
print(customer.seg.svm.tuned)
```
```{r, eval=FALSE}
#View how the performance changes-  Darker regions indicate better accuracy.
plot(customer.seg.svm.tuned)

#Determine the prediction using the best model
customer.seg.svm.best <- customer.seg.svm.tuned$best.model
customer.seg.svm.best.pred <- predict(customer.seg.svm.best, customer.segements.test) 
#print the confusion matrix
conf.mat.svm.best<-table(customer.seg.svm.best.pred, customer.segements.test$segment)
conf.mat.svm.best
#Determine the accuracy
conf.mat.svm.best.accuracy<- sum(diag(conf.mat.svm.best)) / sum(conf.mat.svm.best)
conf.mat.svm.best.accuracy

```

# Second Method: predict the specific lifespan of each customer

# Second Method: classification

```{r}
customer.classify <- customer.data[, c("id", "date", "status", "pages", "onsite", "entered", "completed", "holiday", "gender")] %>% group_by(id)
customer.classify <-customer.classify %>% mutate(avgOnsite = mean(onsite))
customer.classify <-customer.classify %>% mutate(medOnsite = median(onsite))
customer.classify <-customer.classify %>% mutate(sdOnsite = sd(onsite))
customer.classify <-customer.classify %>% mutate(skewOnsite = skewness(onsite))
customer.classify <-customer.classify %>% mutate(avgPages = mean(pages))
customer.classify <-customer.classify %>% mutate(medPages = median(pages))
customer.classify <-customer.classify %>% mutate(sdPages = sd(pages))
customer.classify <-customer.classify %>% mutate(skewPages = skewness(pages))
customer.classify <-customer.classify %>% mutate(avgEntered = mean(entered))
customer.classify <-customer.classify %>% mutate(avgCompleted = mean(completed))
customer.classify <-customer.classify %>% mutate(avgHoliday = mean(holiday))
customer.classify<-customer.classify %>% mutate(enterPerPage = mean(entered/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% mutate(completePerEnter = sum(completed)/sum(entered))
customer.classify<-customer.classify %>% mutate(onsitePerEnter = sum(onsite)/sum(entered))
customer.classify<-customer.classify %>% mutate(onsitePerPage = mean(onsite/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% mutate(pagesPerHoliday = mean(holiday/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% mutate(onsitePerHoliday = mean(holiday/onsite, na.rm = TRUE))
customer.classify <-customer.classify %>% mutate(LastMonthOnsiteTime = tail(onsite, n=2)[1])
customer.classify <-customer.classify %>% mutate(LastMonthPagesViewed = tail(pages, n=2)[1])

customer.classify <- customer.classify %>% distinct(id, .keep_all = TRUE)
customer.classify <- transform(
  customer.classify,
  status = aggregatedCustomerSums$status,
  pages = aggregatedCustomerSums$pages,
  onsite = aggregatedCustomerSums$onsite,
  entered = aggregatedCustomerSums$entered,
  completed = aggregatedCustomerSums$completed,
  holiday = aggregatedCustomerSums$holiday
)

customer.classify<-transform(
  customer.classify,
  status = as.factor(status)
)
```

```{r}
#customer.classify.drop <- c("id","date","pages","onsite","entered","completed","holiday")
customer.classify.drop <- c("id","date")
customer.classify <- customer.classify[,!(names(customer.classify) %in% customer.classify.drop)]
```

```{r}
# Classification method for task 1
# Define training set
set.seed(42)
classify.train<-sample(1:nrow(customer.classify), nrow(customer.classify)*2/3)
customer.classify.train <- customer.classify[classify.train,]
customer.classify.test <- customer.classify[-classify.train,]
```

```{r,cache = true}
# Logistic Regression
customer.classify.logit <- glm(as.factor(status)~., data = customer.classify.train, family=binomial)
customer.classify.logit.probs <- predict(customer.classify.logit, customer.classify.test, type="response")
summary(customer.classify.logit)

customer.classify.logit.pred = rep("1",nrow(customer.classify.test))
customer.classify.logit.pred[customer.classify.logit.probs>0.5] = "2"

customer.classify.logit.table <- table(customer.classify.logit.pred, customer.classify.test$status)
customer.classify.logit.table

# calculate the accuracy of our Logistic Regression model
customer.classify.logit.misclass <- mean(customer.classify.logit.pred != customer.classify.test$status)
customer.classify.logit.accuracy <- 1 - customer.classify.logit.misclass
customer.classify.logit.accuracy
```

```{r,cache = true}
# Random Forest
# build the random forest model for classification
customer.classify.rf <- randomForest(status~., data=customer.classify.train, ntree=500, proximity=T,na.action = na.roughfix)
customer.classify.rf
customer.classify.rf.predict <- predict(customer.classify.rf, customer.classify.test)
customer.classify.rf.table <- table(customer.classify.rf.predict, customer.classify.test$status)
customer.classify.rf.table

# calculate the accuracy of our random forest model
customer.classify.rf.misclass = mean(customer.classify.rf.predict != customer.classify.test$status)
customer.classify.rf.accuracy <- 1- customer.classify.rf.misclass
customer.classify.rf.accuracy
```

```{r}
# Naive Bayes
customer.classify.nb <-naiveBayes(status ~., data = customer.classify.train, laplace=1)
summary(customer.classify.nb)
customer.classify.nb.pred <- predict(customer.classify.nb, customer.classify.test)

customer.classify.nb.table<-table(customer.classify.nb.pred, customer.classify.test$status)
customer.classify.nb.table

# calculate the accuracy of our Naive Bayes model
customer.classify.nb.misclass = mean(customer.classify.nb.pred != customer.classify.test$status)
customer.classify.nb.accuracy <- 1- customer.classify.nb.misclass
customer.classify.nb.accuracy
```

```{r}
#SVM
customer.classify.svm <-svm(status~ . , data = customer.classify.train, type = 'C-classification', kernel = 'radial')
customer.classify.svm.pred <- predict(customer.classify.svm, customer.classify.test)

customer.classify.svm.table<-table(customer.classify.svm.pred, customer.classify.test$status)
customer.classify.svm.table

# calculate the accuracy of our svm model
customer.classify.svm.misclass = mean(customer.classify.svm.pred != customer.classify.test$status)
customer.classify.svm.accuracy <- 1- customer.classify.svm.misclass
customer.classify.svm.accuracy
```


## 2.	Develop a model for estimating the ltv of a customer. Characterize your model performance.

```{r}
```

## 3.	Develop a customer segmentation scheme. Include in this scheme the identification of sleeping customers, those that are no longer active but have not canceled their account.

# Segmentation 1: Segmentation 1: Regular(users who have completed regularly irrespective of holidays), Sleeping, Holiday User(holiday based customers),  Inactive (canceled)

- Variables: Completed, pages, onsite, entered
- Classification label: Regular/Sleeping/Inactive
  - 3: if the customer has browsed the website >60 days of `12/31/2014` then classify the customer as sleeping.
  - 2: if all the variables of related to that customer is 0 then we classfy the customer as a inactive.
  - 1: if the customer has recently browsed the website has been active within 60 days of `12/31/2014` then classify the customer as active.

- data preprocssing:
```{r}
aggregatedCustomerSums$holiday.ratio <- aggregatedCustomerSums$holiday/aggregatedCustomerSums$completed
summary(aggregatedCustomerSums$holiday.ratio)
```
```{r}
aggregatedCustomerSums$holiday.user <- ifelse(aggregatedCustomerSums$holiday.ratio>0.4573,1,0)
```

active = 1
Sleeping = 2
Inactive (canceled) = 3
```{r}
width = length(customer.data)
len = length(customer.data$id)
user.type = rep(0, times = len)
previd = customer.data[1][1]
startid = previd
for(i in seq(len)){
  startid = customer.data[i,1]
  if(customer.data[i,2] == 2){
    user.type[i] = 3
  }else if(startid!=previd){
    diff = (as.Date('12/31/2014','%m/%d/%Y') - customer.data[i-1,4])
    if(diff>60){
      user.type[i-1] = 2
      user.type[i] = 1
    }else{
      user.type[i] = 1
    }
  }else{
    user.type[i] = 1
  }
  previd = startid
}
customer.data$userType <- user.type
```


```{r}
#select the data we need, we do not want to overfit the model, and hence will only include data only the 
# maxDate related data for the each user.
customer.data.segOne <- customer.data %>% group_by(id) %>% filter(date == max(date)) 
customer.data.segOne <- subset(customer.data.segOne,select = c('pages','onsite', 'userType'))#, 'entered', 'completed'))
#split into training and test dataset
customer.data.segOne <- transform(
  customer.data.segOne,
  pages=as.integer(pages),
  onsite=as.integer(onsite),
  userType = as.factor(userType)
)
dt = sort(sample(nrow(customer.data.segOne), nrow(customer.data.segOne)*.7))
train.segOne<-customer.data.segOne[dt,]
test.segOne<-customer.data.segOne[-dt,]

```

#random forest
```{r}
set.seed(1)
customer.segOne.rf <- randomForest(
  as.factor(userType) ~ ., 
  data = train.segOne, 
  importance = TRUE,
  num.trees = 500
)

customer.segOne.rf

varImpPlot(customer.segOne.rf)

customer.segOne.pred <- predict(customer.segOne.rf, test.segOne)
customer.segOne.rfResult<- table(test.segOne$userType, customer.segOne.pred)
customer.segOne.rfResult
accuracy<- sum(diag(customer.segOne.rfResult)) / sum(customer.segOne.rfResult)
accuracy
```

# Logistic Regression

```{r}
#create the logistic regression model with output as userType and inputs as pages, onsite, entered and completed.
customer.segOne.lr <- multinom(train.segOne$userType ~ . , data = train.segOne)
customer.segOne.lr
#test the model classification on the test data
customer.segOne.lr.pred <- predict(customer.segOne.lr,newdata=test.segOne)
#create a confusion matrix
customer.segOne.lr.conf <-table(customer.segOne.lr.pred, test.segOne$userType)
prop.table(customer.segOne.lr.conf)
#determine the accuracy of the model
customer.segOne.lr.accuracy<- sum(diag(customer.segOne.lr.conf)) / sum(customer.segOne.lr.conf)
customer.segOne.lr.accuracy
```

# Naive Bayes

```{r}
#Construct a naive bayes classification model on the train data set
customer.segOne.nb <-naiveBayes(train.segOne$userType ~ ., data = train.segOne)
customer.segOne.nb
#test the model classification on the test data
customer.segOne.nb.pred <- predict(customer.segOne.nb, newdata=test.segOne)
#create a confusion matrix
customer.segOne.nb.conf <-table(customer.segOne.nb.pred, test.segOne$userType)
prop.table(customer.segOne.nb.conf)
#determine the accuracy of the model
customer.segOne.nb.accuracy<- sum(diag(customer.segOne.nb.conf)) / sum(customer.segOne.nb.conf)
customer.segOne.nb.accuracy
```
# Segmentation 2: Decisive customers, Tentative customers, Hesitant customers
- Variables: Gender, onsite, pages, entered, completed
- Classification label: completed / entered 
  - 2: if the `decisiveratio` of that customer is greater or equal to `r summary(aggregatedCustomerSums$decisiveratio)[5]` then we classfy the customer as decisive
  - 1: if the `decisiveratio` of that customer fall in the range of `r summary(aggregatedCustomerSums$decisiveratio)[2]` and `r summary(aggregatedCustomerSums$decisiveratio)[5]`, then we classfy the customer as tentative
  - 0: if the `decisiveratio` of that customer is smaller than `r summary(aggregatedCustomerSums$decisiveratio)[2]` , then we classfy the customer as hesitant

```{r}
summary(aggregatedCustomerSums$decisiveratio)
```


```{r}
# create data labels 
decisivelabel <- with(aggregatedCustomerSums, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[5], 2, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[2],1,0)))
# merge the created label with selected data
decisive.data <- data.frame(aggregatedCustomerSums[c("pages", "onsite","holiday","gender","lifespan")], decisivelabel = as.factor(decisivelabel))
set.seed(42)
# separate data into train, test data
#randomly get 2/3 data of each label into train data, 1/3 data of each label into test data
hesitant<-subset(decisive.data, decisivelabel == 0)
tentative<-subset(decisive.data, decisivelabel == 1)
decisive<-subset(decisive.data, decisivelabel == 2)
train.h<-hesitant[sample(nrow(hesitant),), ][c(1:1658), ]
test.h<-hesitant[sample(nrow(hesitant),), ][c(1659:2487), ]
train.t<-tentative[sample(nrow(tentative),), ][c(1:3155),]
test.t<-tentative[sample(nrow(tentative),), ][c(3156:4732),]
train.d<-decisive[sample(nrow(decisive),), ][c(1:1854),]
test.d<-decisive[sample(nrow(decisive),), ][c(1854:2781),]
decisive.train<-rbind(train.h, train.t, train.d)
decisive.test<-rbind(test.h, test.t, test.d)
```

```{r, cache = TRUE}
# Random Forest
# build the random forest model for classification
customer.rf <- randomForest(decisivelabel~., data=decisive.train, ntree=500, proximity=T)
customer.rf
customer.rf.predict <- predict(customer.rf, decisive.test)
customer.rf.table <- table(customer.rf.predict, decisive.test$decisivelabel)
customer.rf.table
# calculate the accuracy of our random forest model
customer.rf.misclassificationrate = mean(customer.rf.predict != decisive.test$decisivelabel)
customer.rf.accuracy <- 1- customer.rf.misclassificationrate
customer.rf.accuracy
```


```{r}
# KNN
train_control <- trainControl(method = "cv", number = 10)
customer.knn <- train(decisivelabel~., data = decisive.train, trControl = train_control, method = "knn")
customer.knn
customer.knn.predict <- predict(customer.knn, decisive.test)
customer.knn.table <- table(customer.knn.predict, decisive.test$decisivelabel)
customer.knn.table
# calculate the accuracy of our random forest model
customer.knn.misclassificationrate = mean(customer.knn.predict != decisive.test$decisivelabel)
customer.knn.accuracy <- 1- customer.knn.misclassificationrate
customer.knn.accuracy
```

```{r}
# Mulrinomial Logistic Regression
decisve.ml <- multinom(decisivelabel ~ . , data = decisive.train)
decisve.ml
logit.pred <- decisve.ml %>% predict(decisive.test)
conf.mat.logit<-table(logit.pred, decisive.test$decisivelabel)
conf.mat.logit
logit.accuracy<- sum(diag(conf.mat.logit)) / sum(conf.mat.logit)
logit.accuracy
```

```{r}
# Naive Bayes
decisive.nb <-naiveBayes(decisivelabel ~ . , data = decisive.train, laplace=1)
decisive.nb.pred <- predict(decisive.nb, decisive.test)
conf.mat.nb<-table(decisive.nb.pred, decisive.test$decisivelabel)
conf.mat.nb
nb.accuracy<- sum(diag(conf.mat.nb)) / sum(conf.mat.nb)
nb.accuracy
```

```{r}
#SVM
decisive.svm <-svm(decisivelabel ~ . , data = decisive.train, type = 'C-classification', kernel = 'radial')
decisive.svm.pred <- predict(decisive.svm, decisive.test)
conf.mat.svm<-table(decisive.svm.pred, decisive.test$decisivelabel)
conf.mat.svm
svm.accuracy<- sum(diag(conf.mat.svm)) / sum(conf.mat.svm)
svm.accuracy
```

## Random forest is the best

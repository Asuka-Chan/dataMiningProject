segmented.customers.df <- segmented.customers.df %>% dplyr::rename(Type = Group.1)
segmented.customers.df$Type <- c("Sleeping", "Cancelled", "Active", "Napping" )
segmented.customers.df
#Our train set contains all 10,000 users
segmented.customers$segment <- members
#Summary of the customer segmentation data set
kable(summary(segmented.customers), digits = c(3, 3, 3, 3), format = "markdown")
#aggregate the dta
aggregate_customer <- segmented.customers
aggregate_customer$segment.label <- ifelse(aggregate_customer$segment == 1,'sleeping',ifelse(aggregate_customer$segment == 2,'Cancelled',ifelse(aggregate_customer$segment == 3,'Active','Napping')
))
aggregate_customer$status.label <- ifelse(aggregate_customer$lastStatus == 1,'Active User','Non-Active User')
# calculate the normal theoretical quantiles per group
df1 <- ddply(.data = aggregate_customer, .variables = .(status.label,segment.label), function(dat){
q <- qqnorm(dat$completed, plot = FALSE)
dat$xq <- q$x
dat
}
)
# plot the sample values against the theoretical quantiles
ggplot(data = df1, aes(x = xq, y = completed)) +
geom_point() +
labs(title = 'QQ plots', x = 'Normal Quantiles', y = 'Data Completed Quantiles')+
facet_grid(status.label ~ segment.label)
#normalize the lifespan
# standardize the birth weights
aggregate_customer = mutate(aggregate_customer,
lifespan.norm = (lifespan - min(lifespan,na.rm = TRUE))/
(max(lifespan,na.rm = TRUE) - min(lifespan,na.rm = TRUE)))
# calculate the normal theoretical quantiles per group
df2 <- ddply(.data = aggregate_customer, .variables = .(status.label,segment.label), function(dat){
q <- qqnorm(dat$lifespan.norm, plot = FALSE)
dat$xq <- q$x
dat
}
)
# plot the sample values against the theoretical quantiles
ggplot(data = df2, aes(x = xq, y = lifespan.norm)) +
geom_point() +
labs(title = 'QQ plots', x = 'Normal Quantiles', y = 'lifespan Quantiles')+
facet_grid(status.label ~ segment.label)
set.seed(1)
# we create a 70:30 data partition from the subset of customers
train.segments = sample(1:nrow(segmented.customers), nrow(segmented.customers)*2/3)
customer.segements.train <- segmented.customers[train.segments, -4]
customer.segements.test <- segmented.customers[-train.segments, -4]
# Random Forest
customer.segements.rf <- randomForest(as.factor(customer.segements.train$segment) ~ . ,data=customer.segements.train, importance=TRUE, ntree=150)
customer.segements.rf
#plotting the importance of the variables in the model
varImpPlot(customer.segements.rf)
#creating a model to predict the segments that would move into cancellled
customer.segements.rf.predict <- predict(customer.segements.rf, customer.segements.test)
customer.segements.rf.table <- table(customer.segements.rf.predict, customer.segements.test$segment)
customer.segements.rf.table
# display the measurement of confusion martixs
classMetrics(customer.segements.rf.table)
#Creating the model
customer.segements.svm <-svm(as.factor(customer.segements.train$segment) ~ . , data = customer.segements.train)
customer.segements.svm
#We now develop the predict model given the svm model
customer.segements.svm.pred <- predict(customer.segements.svm, customer.segements.test)
#Confusion matric for the same
conf.mat.segments.svm<-table(customer.segements.svm.pred, customer.segements.test$segment)
conf.mat.segments.svm
# display the measurement of confusion martixs
classMetrics(conf.mat.segments.svm)
# Plot the performance of each model
roc.Class1.rf <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.rf.predict))
rs <- roc.Class1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Cluster-Classification ROC")
roc.Class1.svm <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.svm.pred))
rs <- roc.Class1.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
#group the selected columns based on the customer ID
customer.classify <- customer.data[, c("id", "date", "status", "pages", "onsite", "entered", "completed", "holiday", "gender")] %>% group_by(id)
#add to the data set, statistical features - mean, median, standard deviation and skewness
customer.classify <-customer.classify %>% dplyr::mutate(avgOnsite = mean(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(medOnsite = median(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(sdOnsite = sd(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(skewOnsite = skewness(onsite))
customer.classify <-customer.classify %>% dplyr::mutate(avgPages = mean(pages))
customer.classify <-customer.classify %>% dplyr::mutate(medPages = median(pages))
customer.classify <-customer.classify %>% dplyr::mutate(sdPages = sd(pages))
customer.classify <-customer.classify %>% dplyr::mutate(skewPages = skewness(pages))
customer.classify <-customer.classify %>% dplyr::mutate(avgEntered = mean(entered))
customer.classify <-customer.classify %>% dplyr::mutate(avgCompleted = mean(completed))
customer.classify <-customer.classify %>% dplyr::mutate(avgHoliday = mean(holiday))
customer.classify<-customer.classify %>% dplyr::mutate(enterPerPage = mean(entered/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% dplyr::mutate(completePerEnter = sum(completed)/sum(entered))
customer.classify<-customer.classify %>% dplyr::mutate(onsitePerEnter = sum(onsite)/sum(entered))
customer.classify<-customer.classify %>% dplyr::mutate(onsitePerPage = mean(onsite/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% dplyr::mutate(pagesPerHoliday = mean(holiday/pages, na.rm = TRUE))
customer.classify<-customer.classify %>% dplyr::mutate(onsitePerHoliday = mean(holiday/onsite, na.rm = TRUE))
customer.classify <-customer.classify %>% dplyr::mutate(LastMonthOnsiteTime = tail(onsite, n=2)[1])
customer.classify <-customer.classify %>% dplyr::mutate(LastMonthPagesViewed = tail(pages, n=2)[1])
#Ensure the set only contains distinct values for ID
customer.classify <- customer.classify %>% dplyr::distinct(id, .keep_all = TRUE)
#add in the below columns from the aggregatedCustomerSums dataset
customer.classify <- transform(
customer.classify,
status = aggregatedCustomerSums$status,
pages = aggregatedCustomerSums$pages,
onsite = aggregatedCustomerSums$onsite,
entered = aggregatedCustomerSums$entered,
completed = aggregatedCustomerSums$completed,
holiday = aggregatedCustomerSums$holiday
)
customer.classify<-transform(
customer.classify,
status = as.factor(status)
)
#Summary of the customer classification pre-processed data set
kable(summary(customer.classify), digits = c(3, 3, 3, 3), format = "markdown")
customer.classify.drop <- c("id","date")
customer.classify <- customer.classify[,!(names(customer.classify) %in% customer.classify.drop)]
# Classification method for task 1
# Define training set
set.seed(42)
classify.train<-sample(1:nrow(customer.classify), nrow(customer.classify)*2/3)
customer.classify.train <- customer.classify[classify.train,]
customer.classify.test <- customer.classify[-classify.train,]
#create the logistic regression model and use the model for predicting using the test set
customer.classify.logit <- glm(as.factor(status)~., data = customer.classify.train, family="binomial")
customer.classify.logit.probs <- predict(customer.classify.logit, customer.classify.test, type="response")
summary(customer.classify.logit)
#Using alpha as 0.5, classify predictions as 2 if the values are above 0.5
customer.classify.logit.pred = rep("1",nrow(customer.classify.test))
customer.classify.logit.pred[customer.classify.logit.probs>0.5] = "2"
#Display the confusion matrix
customer.classify.logit.table <- table(customer.classify.logit.pred, customer.classify.test$status)
customer.classify.logit.table
# display the measurement of confusion martixs
classMetrics(customer.classify.logit.table)
# build the random forest model for classification
customer.classify.rf <- randomForest(status~., data=customer.classify.train, ntree=500, proximity=T,na.action = na.roughfix)
customer.classify.rf
customer.classify.rf.predict <- predict(customer.classify.rf, customer.classify.test)
customer.classify.rf.table <- table(customer.classify.rf.predict, customer.classify.test$status)
customer.classify.rf.table
# display the measurement of confusion martixs
classMetrics(customer.classify.rf.table)
# build the naive bayes model
customer.classify.nb <-naiveBayes(status ~., data = customer.classify.train, laplace=1)
summary(customer.classify.nb)
customer.classify.nb.pred <- predict(customer.classify.nb, customer.classify.test)
customer.classify.nb.table<-table(customer.classify.nb.pred, customer.classify.test$status)
customer.classify.nb.table
# display the measurement of confusion martixs
classMetrics(customer.classify.nb.table)
# create the SVM model
customer.classify.svm <-svm(status~ . , data = customer.classify.train, type = 'C-classification', kernel = 'radial')
customer.classify.svm.pred <- predict(customer.classify.svm, customer.classify.test)
customer.classify.svm.table<-table(customer.classify.svm.pred, customer.classify.test$status)
customer.classify.svm.table
# display the measurement of confusion martixs
classMetrics(customer.classify.svm.table)
# Plotthe performance of each model
roc.Class2.rf <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.rf.predict))
rs <- roc.Class2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Direct Classification ROC")
roc.Class2.logit <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.logit.pred))
rs <- roc.Class2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Class2.nb <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.nb.pred))
rs <- roc.Class2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Class2.svm <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.svm.pred))
rs <- roc.Class2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
aggregatedCustomerSumsTask2 <- transform(
aggregatedCustomerSums,
lifespanByMonth = ceiling(lifespan/30)
)
aggregatedCustomerSumsTask2.drop <- c("id","status","gender","lifespan","decisiveratio","holiday.ratio","holiday.user")
aggregatedCustomerSumsTask2 <- aggregatedCustomerSumsTask2[,!(names(aggregatedCustomerSumsTask2) %in% aggregatedCustomerSumsTask2.drop)]
set.seed(42)
#K-means Clustering
aggregatedCustomerSumsTask2 <- na.omit(aggregatedCustomerSumsTask2) # listwise deletion of missing
std.aggregatedCustomerSumsTask2 <- rescale(data.matrix(std.aggregatedCustomerSumsTask2)) # standardize variables
library(oce)
install.packages("oce")
library(oce)
set.seed(42)
#K-means Clustering
aggregatedCustomerSumsTask2 <- na.omit(aggregatedCustomerSumsTask2) # listwise deletion of missing
std.aggregatedCustomerSumsTask2 <- rescale(data.matrix(std.aggregatedCustomerSumsTask2)) # standardize variables
aggregatedCustomerSums$holiday.ratio <- aggregatedCustomerSums$holiday/aggregatedCustomerSums$completed
summary(aggregatedCustomerSums$holiday.ratio)
aggregatedCustomerSums$holiday.user <- ifelse(aggregatedCustomerSums$holiday.ratio>0.4573,1,0)
width = length(customer.data)
len = length(customer.data$id)
user.type = rep(0, times = len)
previd = customer.data[1][1]
startid = previd
for(i in seq(len)){
startid = customer.data[i,1]
if(customer.data[i,2] == 2){
user.type[i] = 3
}else if(startid!=previd){
diff = (as.Date('12/31/2014','%m/%d/%Y') - customer.data[i-1,4])
if(diff>60){
user.type[i-1] = 2
user.type[i] = 1
}else{
user.type[i] = 1
}
}else{
user.type[i] = 1
}
previd = startid
}
customer.data$userType <- user.type
View(customer.data)
View(customer.data)
#select the data we need, we do not want to overfit the model, and hence will only include all the data.
# maxDate related data for the each user.
customer.data.segOne <- customer.data %>% group_by(id) %>% filter(date == max(date))
customer.data.segOne <- subset(customer.data.segOne,select = c('pages','onsite', 'userType'))#, 'entered', 'completed'))
#split into training and test dataset
customer.data.segOne <- transform(
customer.data.segOne,
pages=as.integer(pages),
onsite=as.integer(onsite),
userType = as.factor(userType)
)
#Summary of the customer classification for differnet user type
kable(summary(customer.data.segOne), digits = c(3, 3, 3, 3), format = "markdown")
set.seed(1)
dt = sort(sample(nrow(customer.data.segOne), nrow(customer.data.segOne)*.7))
train.segOne<-customer.data.segOne[dt,]
test.segOne<-customer.data.segOne[-dt,]
View(customer.data.segOne)
customer.segOne.rf <- randomForest(
as.factor(userType) ~ .,
data = train.segOne,
importance = TRUE,
num.trees = 500
)
customer.segOne.rf
varImpPlot(customer.segOne.rf)
customer.segOne.pred <- predict(customer.segOne.rf, test.segOne)
customer.segOne.rfResult<- table(test.segOne$userType, customer.segOne.pred)
customer.segOne.rfResult
# display the measurement of confusion martixs
classMetrics(customer.segOne.rfResult)
library(oce)
set.seed(42)
#K-means Clustering
aggregatedCustomerSumsTask2 <- na.omit(aggregatedCustomerSumsTask2) # listwise deletion of missing
std.aggregatedCustomerSumsTask2 <- rescale(data.matrix(aggregatedCustomerSumsTask2)) # standardize variables
wss <- (nrow(std.aggregatedCustomerSumsTask2)-1)*sum(apply(std.aggregatedCustomerSumsTask2,2,var))
#select the data we need, we do not want to overfit the model, and hence will only include all the data.
# maxDate related data for the each user.
customer.data.segOne <- customer.data %>% group_by(id) %>% filter(date == max(date))
customer.data.segOne <- subset(customer.data.segOne,select = c('pages','onsite', 'userType'))
#split into training and test dataset
customer.data.segOne <- transform(
customer.data.segOne,
pages=as.integer(pages),
onsite=as.integer(onsite),
userType = as.factor(userType)
)
#Summary of the customer classification for differnet user type
kable(summary(customer.data.segOne), digits = c(3, 3, 3, 3), format = "markdown")
set.seed(1)
dt = sort(sample(nrow(customer.data.segOne), nrow(customer.data.segOne)*.7))
train.segOne<-customer.data.segOne[dt,]
test.segOne<-customer.data.segOne[-dt,]
customer.segOne.rf <- randomForest(
as.factor(userType) ~ .,
data = train.segOne,
importance = TRUE,
num.trees = 500
)
customer.segOne.rf
varImpPlot(customer.segOne.rf)
customer.segOne.pred <- predict(customer.segOne.rf, test.segOne)
customer.segOne.rfResult<- table(test.segOne$userType, customer.segOne.pred)
customer.segOne.rfResult
# display the measurement of confusion martixs
classMetrics(customer.segOne.rfResult)
#create the logistic regression model with output as userType and inputs as pages, onsite, entered and completed.
customer.segOne.lr <- multinom(train.segOne$userType ~ . , data = train.segOne)
customer.segOne.lr
#test the model classification on the test data
customer.segOne.lr.pred <- predict(customer.segOne.lr,newdata=test.segOne)
#create a confusion matrix
customer.segOne.lr.conf <-table(customer.segOne.lr.pred, test.segOne$userType)
prop.table(customer.segOne.lr.conf)
# display the measurement of confusion martixs
classMetrics(customer.segOne.lr.conf)
#Construct a naive bayes classification model on the train data set
customer.segOne.nb <-naiveBayes(train.segOne$userType ~ ., data = train.segOne)
customer.segOne.nb
#test the model classification on the test data
customer.segOne.nb.pred <- predict(customer.segOne.nb, newdata=test.segOne)
#create a confusion matrix
customer.segOne.nb.conf <-table(customer.segOne.nb.pred, test.segOne$userType)
prop.table(customer.segOne.nb.conf)
# display the measurement of confusion martixs
classMetrics(customer.segOne.nb.conf)
# Plotthe performance of each model
roc.Seg1.rf <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.pred))
rs <- roc.Seg1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 1 ROC")
roc.Seg1.logit <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.lr.pred))
rs <- roc.Seg1.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg1.nb <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.nb.pred))
rs <- roc.Seg1.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
aggregatedCustomerSumsTask2 <- transform(
aggregatedCustomerSums,
lifespanByMonth = ceiling(lifespan/30)
)
aggregatedCustomerSumsTask2.drop <- c("id","status","gender","lifespan","decisiveratio","holiday.ratio","holiday.user")
aggregatedCustomerSumsTask2 <- aggregatedCustomerSumsTask2[,!(names(aggregatedCustomerSumsTask2) %in% aggregatedCustomerSumsTask2.drop)]
set.seed(42)
#K-means Clustering
aggregatedCustomerSumsTask2 <- na.omit(aggregatedCustomerSumsTask2) # listwise deletion of missing
std.aggregatedCustomerSumsTask2 <- rescale(data.matrix(aggregatedCustomerSumsTask2)) # standardize variables
wss <- (nrow(std.aggregatedCustomerSumsTask2)-1)*sum(apply(std.aggregatedCustomerSumsTask2,2,var))
summary(aggregatedCustomerSums$decisiveratio)
# create data labels
decisivelabel <- with(aggregatedCustomerSums, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[5], 2, ifelse(decisiveratio >= summary(aggregatedCustomerSums$decisiveratio)[2],1,0)))
# merge the created label with selected data
decisive.data <- data.frame(aggregatedCustomerSums[c("pages", "onsite","holiday","gender","lifespan")], decisivelabel = as.factor(decisivelabel))
set.seed(42)
# separate data into train, test data
#randomly get 2/3 data of each label into train data, 1/3 data of each label into test data
hesitant<-subset(decisive.data, decisivelabel == 0)
tentative<-subset(decisive.data, decisivelabel == 1)
decisive<-subset(decisive.data, decisivelabel == 2)
train.h<-hesitant[sample(nrow(hesitant),), ][c(1:1658), ]
test.h<-hesitant[sample(nrow(hesitant),), ][c(1659:2487), ]
train.t<-tentative[sample(nrow(tentative),), ][c(1:3155),]
test.t<-tentative[sample(nrow(tentative),), ][c(3156:4732),]
train.d<-decisive[sample(nrow(decisive),), ][c(1:1854),]
test.d<-decisive[sample(nrow(decisive),), ][c(1854:2781),]
decisive.train<-rbind(train.h, train.t, train.d)
decisive.test<-rbind(test.h, test.t, test.d)
View(decisive.train)
View(decisive.train)
library(tidyverse)
library(ggplot2)
library(ISLR)
library(partykit)
library(caret)
library(rpart)
library(randomForest)
library(pROC)
library(binaryLogic)
library(dplyr)
library(class)
library(DMwR)
library(nnet)
library(e1071)
library(ranger)
library(glmnet)
library(cluster)
library(ggdendro)
library(knitr)
library(readxl)
library(factoextra)
library(scales)
aggregatedCustomerSumsTask2 <- transform(
aggregatedCustomerSums,
lifespanByMonth = ceiling(lifespan/30)
)
aggregatedCustomerSumsTask2.drop <- c("id","status","gender","lifespan","decisiveratio","holiday.ratio","holiday.user")
aggregatedCustomerSumsTask2 <- aggregatedCustomerSumsTask2[,!(names(aggregatedCustomerSumsTask2) %in% aggregatedCustomerSumsTask2.drop)]
set.seed(42)
#K-means Clustering
aggregatedCustomerSumsTask2 <- na.omit(aggregatedCustomerSumsTask2) # listwise deletion of missing
std.aggregatedCustomerSumsTask2 <- rescale(data.matrix(aggregatedCustomerSumsTask2)) # standardize variables
wss <- (nrow(std.aggregatedCustomerSumsTask2)-1)*sum(apply(std.aggregatedCustomerSumsTask2,2,var))
for (i in 2:15) wss[i] <- sum(kmeans(std.aggregatedCustomerSumsTask2,
centers=i)$withinss)
plot(1:15, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
km.ltv <- kmeans(std.aggregatedCustomerSumsTask2, 3, nstart = 25)
str(km.ltv)
fviz_cluster(km.ltv, data = std.aggregatedCustomerSumsTask2)
# decreasing the segments to 4
clustered.ltv <- data.frame(km.ltv$centers)
clustered.ltv <- data.frame(Type = c("Medium LTV", "High LTV", "Low LTV"),clustered.ltv)
clustered.ltv <- transform (
clustered.ltv,
pages = pages * max(aggregatedCustomerSumsTask2),
onsite = onsite * max(aggregatedCustomerSumsTask2),
entered = entered * max(aggregatedCustomerSumsTask2),
completed = completed * max(aggregatedCustomerSumsTask2),
lifespanByMonth = lifespanByMonth * max(aggregatedCustomerSumsTask2)
)
clustered.ltv$lifetimeValue = clustered.ltv$lifespanByMonth * 1
clustered.ltv
# Plotthe performance of each model
roc.Seg1.rf <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.pred))
rs <- roc.Seg1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 1 ROC")
roc.Seg1.logit <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.lr.pred))
rs <- roc.Seg1.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg1.nb <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.nb.pred))
rs <- roc.Seg1.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
# build the random forest model for classification
customer.rf <- randomForest(decisivelabel~., data=decisive.train, ntree=500, proximity=T)
customer.rf
customer.rf.predict <- predict(customer.rf, decisive.test)
customer.rf.table <- table(customer.rf.predict, decisive.test$decisivelabel)
customer.rf.table
# display the measurement of confusion martixs
classMetrics(customer.rf.table)
train_control <- trainControl(method = "cv", number = 10)
customer.knn <- train(decisivelabel~., data = decisive.train, trControl = train_control, method = "knn")
customer.knn
customer.knn.predict <- predict(customer.knn, decisive.test)
customer.knn.table <- table(customer.knn.predict, decisive.test$decisivelabel)
customer.knn.table
# display the measurement of confusion martixs
classMetrics(customer.knn.table)
decisve.ml <- multinom(decisivelabel ~ . , data = decisive.train)
decisve.ml
logit.pred <- decisve.ml %>% predict(decisive.test)
conf.mat.logit<-table(logit.pred, decisive.test$decisivelabel)
conf.mat.logit
# display the measurement of confusion martixs
classMetrics(conf.mat.logit)
decisive.nb <-naiveBayes(decisivelabel ~ . , data = decisive.train, laplace=1)
decisive.nb.pred <- predict(decisive.nb, decisive.test)
conf.mat.nb<-table(decisive.nb.pred, decisive.test$decisivelabel)
conf.mat.nb
# display the measurement of confusion martixs
classMetrics(conf.mat.nb)
decisive.svm <-svm(decisivelabel ~ . , data = decisive.train, type = 'C-classification', kernel = 'radial')
decisive.svm.pred <- predict(decisive.svm, decisive.test)
conf.mat.svm<-table(decisive.svm.pred, decisive.test$decisivelabel)
conf.mat.svm
# display the measurement of confusion martixs
classMetrics(conf.mat.svm)
# Plotthe performance of each model
roc.Seg2.rf <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.rf.predict))
rs <- roc.Seg2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 2 ROC")
roc.Seg2.knn <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.knn.predict))
rs <- roc.Seg2.knn[['rocs']]
plot(rs[[1]], col = "steelblue", lty = 3, add = TRUE)
roc.Seg2.logit <- multiclass.roc(decisive.test$decisivelabel, as.numeric(logit.pred))
rs <- roc.Seg2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg2.nb <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.nb.pred))
rs <- roc.Seg2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Seg2.svm <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.svm.pred))
rs <- roc.Seg2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
# Plot the performance of each model
roc.Class1.rf <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.rf.predict))
rs <- roc.Class1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Cluster-Classification ROC")
roc.Class1.svm <- multiclass.roc(customer.segements.test$segment, as.numeric(customer.segements.svm.pred))
rs <- roc.Class1.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","SVM","SVM Best"), col = c("red","green","blue"),
lty = c(2,3,3), pch = c(-1, -1, -1))
# Plotthe performance of each model
roc.Class2.rf <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.rf.predict))
rs <- roc.Class2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Task1 Direct Classification ROC")
roc.Class2.logit <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.logit.pred))
rs <- roc.Class2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Class2.nb <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.nb.pred))
rs <- roc.Class2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Class2.svm <- multiclass.roc(customer.classify.test$status, as.numeric(customer.classify.svm.pred))
rs <- roc.Class2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","Logistic Regression","Naive Bayes","SVM"), col = c("red","black","blue","green"),
lty = c(2,3,3,3), pch = c(-1, -1, -1, -1))
# Plotthe performance of each model
roc.Seg1.rf <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.pred))
rs <- roc.Seg1.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 1 ROC")
roc.Seg1.logit <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.lr.pred))
rs <- roc.Seg1.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg1.nb <- multiclass.roc(test.segOne$userType, as.numeric(customer.segOne.nb.pred))
rs <- roc.Seg1.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","Logistic Regression","Naive Bayes"), col = c("red","black","blue"),
lty = c(2,3,3), pch = c(-1, -1, -1))
# Plotthe performance of each model
roc.Seg2.rf <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.rf.predict))
rs <- roc.Seg2.rf[['rocs']]
plot.roc(rs[[1]], col = "red", lty=2, main = "Segmentation 2 ROC")
roc.Seg2.knn <- multiclass.roc(decisive.test$decisivelabel, as.numeric(customer.knn.predict))
rs <- roc.Seg2.knn[['rocs']]
plot(rs[[1]], col = "steelblue", lty = 3, add = TRUE)
roc.Seg2.logit <- multiclass.roc(decisive.test$decisivelabel, as.numeric(logit.pred))
rs <- roc.Seg2.logit[['rocs']]
plot(rs[[1]], col = "black", lty = 3, add = TRUE)
roc.Seg2.nb <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.nb.pred))
rs <- roc.Seg2.nb[['rocs']]
plot(rs[[1]], col = "blue", lty = 3, add = TRUE)
roc.Seg2.svm <- multiclass.roc(decisive.test$decisivelabel, as.numeric(decisive.svm.pred))
rs <- roc.Seg2.svm[['rocs']]
plot(rs[[1]], col = "green", lty = 3, add = TRUE)
legend("bottomright", c("Random Forest","KNN","Logistic Regression","Naive Bayes","SVM"), col = c("red","steelblue","black","blue","green"),
lty = c(2,3,3,3,3), pch = c(-1, -1, -1, -1, -1))
